{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9a044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1373904), (1, 794018)] (2167922,)\n",
      "[(0, 343476), (1, 198505)] (541981,)\n",
      "[(0, 429345), (1, 248131)] (677476,)\n"
     ]
    }
   ],
   "source": [
    "# importing file reading, sampling, model, evaluation, visualization libraries\n",
    "import os,pandas as pd,numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# setting up working directory\n",
    "os.chdir(\"C:\\\\Users\\\\25273141\\\\OneDrive - Edge Hill University\\\\Publish\\\\Data\\\\Irish Loan Data\\\\loan\")\n",
    "\n",
    "# reading the train csv file from local system\n",
    "loan_raw_train=pd.read_csv(\"xy_raw_train_publish.csv\", header =0).round(0)\n",
    "required_columns=['emp_length_int', 'home_ownership', 'home_ownership_cat','income_category', 'annual_inc', 'income_cat', 'loan_amount', 'term','term_cat', 'application_type', 'application_type_cat', 'purpose','purpose_cat', 'interest_payments', 'interest_payment_cat','interest_rate', 'grade', 'grade_cat', 'dti','total_pymnt', 'total_rec_prncp', 'recoveries', 'installment','region']\n",
    "X_raw_train=loan_raw_train.loc[:,required_columns]\n",
    "\n",
    "#convert some variables into categoricals\n",
    "req_numbers = [X_raw_train.columns.get_loc(col) for col in required_columns]\n",
    "categorical_columns=['home_ownership','home_ownership_cat','income_category','income_cat','term','term_cat','application_type','application_type_cat','purpose','purpose_cat','interest_payment_cat','grade','grade_cat', 'region']\n",
    "cat_numbers = [X_raw_train.columns.get_loc(col) for col in categorical_columns]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for i in cat_numbers:\n",
    "    X_raw_train.iloc[:,i] = label_encoder.fit_transform(X_raw_train.iloc[:,i])\n",
    "    X_raw_train.iloc[:,i] = X_raw_train.iloc[:,i].astype('category')\n",
    "\n",
    "# keep output variable in y dataset\n",
    "y_raw_train=loan_raw_train.iloc[:,27]\n",
    "\n",
    "# reading the train csv file from local system\n",
    "loan_train=pd.read_csv(\"xy_train_publish.csv\", header =0).round(0)\n",
    "X_train=loan_train.loc[:,required_columns]\n",
    "\n",
    "#convert some variables into categoricals\n",
    "req_numbers = [X_train.columns.get_loc(col) for col in required_columns]\n",
    "cat_numbers = [X_train.columns.get_loc(col) for col in categorical_columns]\n",
    "for i in cat_numbers:\n",
    "    X_train.iloc[:,i] = label_encoder.fit_transform(X_train.iloc[:,i])\n",
    "    X_train.iloc[:,i] = X_train.iloc[:,i].astype('category')\n",
    "\n",
    "# keep output variable in y dataset\n",
    "y_train=loan_train.iloc[:,27]\n",
    "print(sorted(Counter(y_train).items()), y_train.shape)\n",
    "# reading the test csv file from local system\n",
    "loan_test=pd.read_csv(\"xy_test_publish.csv\", header =0).round(0)\n",
    "X_test=loan_test.loc[:,required_columns]\n",
    "\n",
    "#convert some variables into categoricals\n",
    "req_numbers = [X_test.columns.get_loc(col) for col in required_columns]\n",
    "cat_numbers = [X_test.columns.get_loc(col) for col in categorical_columns]\n",
    "for i in cat_numbers:\n",
    "    X_test.iloc[:,i] = label_encoder.fit_transform(X_test.iloc[:,i])\n",
    "    X_test.iloc[:,i] = X_test.iloc[:,i].astype('category')\n",
    "\n",
    "\n",
    "# keep output variable in y dataset\n",
    "y_test=loan_test.iloc[:,27]\n",
    "print(sorted(Counter(y_test).items()), y_test.shape)\n",
    "# reading the train csv file from local system\n",
    "loan_eval=pd.read_csv(\"xy_eval_publish.csv\", header =0).round(0)\n",
    "X_raw_eval=loan_eval.loc[:,required_columns]\n",
    "\n",
    "#convert some variables into categoricals\n",
    "req_numbers = [X_raw_eval.columns.get_loc(col) for col in required_columns]\n",
    "cat_numbers = [X_raw_eval.columns.get_loc(col) for col in categorical_columns]\n",
    "for i in cat_numbers:\n",
    "    X_raw_eval.iloc[:,i] = label_encoder.fit_transform(X_raw_eval.iloc[:,i])\n",
    "    X_raw_eval.iloc[:,i] = X_raw_eval.iloc[:,i].astype('category')\n",
    "\n",
    "# keep output variable in y dataset\n",
    "y_raw_eval=loan_eval.iloc[:,27]\n",
    "print(sorted(Counter(y_raw_eval).items()), y_raw_eval.shape)\n",
    "#create emplty dataframes for storing predicted outputs\n",
    "all_single_model_raw_train_actual_pred=pd.DataFrame()\n",
    "all_single_model_raw_train_actual_pred['index']=range(0,len(y_train))\n",
    "all_single_model_raw_test_actual_pred=pd.DataFrame()\n",
    "all_single_model_raw_test_actual_pred['index']=range(0,len(y_test))\n",
    "all_single_model_raw_eval_actual_pred=pd.DataFrame()\n",
    "all_single_model_raw_eval_actual_pred['index']=range(0,len(y_raw_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6623718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:116: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:120: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:124: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df3_train_test.iloc[:,i] = label_encoder.fit_transform(df3_train_test.iloc[:,i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:124: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df3_train_test.iloc[:,i] = label_encoder.fit_transform(df3_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:124: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df3_train_test.iloc[:,i] = label_encoder.fit_transform(df3_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:124: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df3_train_test.iloc[:,i] = label_encoder.fit_transform(df3_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:124: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df3_train_test.iloc[:,i] = label_encoder.fit_transform(df3_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:124: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df3_train_test.iloc[:,i] = label_encoder.fit_transform(df3_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:128: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df4_train_test.iloc[:,i] = label_encoder.fit_transform(df4_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:128: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df4_train_test.iloc[:,i] = label_encoder.fit_transform(df4_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:128: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df4_train_test.iloc[:,i] = label_encoder.fit_transform(df4_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:128: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df4_train_test.iloc[:,i] = label_encoder.fit_transform(df4_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:128: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df4_train_test.iloc[:,i] = label_encoder.fit_transform(df4_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:128: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df4_train_test.iloc[:,i] = label_encoder.fit_transform(df4_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:132: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df5_train_test.iloc[:,i] = label_encoder.fit_transform(df5_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:132: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df5_train_test.iloc[:,i] = label_encoder.fit_transform(df5_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:132: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df5_train_test.iloc[:,i] = label_encoder.fit_transform(df5_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:132: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df5_train_test.iloc[:,i] = label_encoder.fit_transform(df5_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:132: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df5_train_test.iloc[:,i] = label_encoder.fit_transform(df5_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:132: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df5_train_test.iloc[:,i] = label_encoder.fit_transform(df5_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:136: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df6_train_test.iloc[:,i] = label_encoder.fit_transform(df6_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:136: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df6_train_test.iloc[:,i] = label_encoder.fit_transform(df6_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:136: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df6_train_test.iloc[:,i] = label_encoder.fit_transform(df6_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:136: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df6_train_test.iloc[:,i] = label_encoder.fit_transform(df6_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:136: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df6_train_test.iloc[:,i] = label_encoder.fit_transform(df6_train_test.iloc[:,i])\n",
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_22236\\1552759017.py:136: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df6_train_test.iloc[:,i] = label_encoder.fit_transform(df6_train_test.iloc[:,i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 total records: 496471\n",
      "df2 total records: 281498\n",
      "df3 total records: 304406\n",
      "df4 total records: 271172\n",
      "df5 total records: 277482\n",
      "df6 total records: 298551\n",
      "df1 total records: [(0, 248764), (1, 108468)] (357232,)\n",
      "df2 total records: [(0, 140480), (1, 61244)] (201724,)\n",
      "df3 total records: [(0, 152227), (1, 66722)] (218949,)\n",
      "df4 total records: [(0, 136380), (1, 59112)] (195492,)\n",
      "df5 total records: [(0, 139288), (1, 60712)] (200000,)\n",
      "df6 total records: [(0, 149005), (1, 65197)] (214202,)\n",
      "df1 total records: [(0, 128834), (1, 10405)] (139239,)\n",
      "df2 total records: [(0, 43234), (1, 36540)] (79774,)\n",
      "df3 total records: [(0, 45089), (1, 40368)] (85457,)\n",
      "df4 total records: [(0, 40377), (1, 35303)] (75680,)\n",
      "df5 total records: [(0, 41303), (1, 36179)] (77482,)\n",
      "df6 total records: [(0, 44639), (1, 39710)] (84349,)\n"
     ]
    }
   ],
   "source": [
    "# setting up working directory\n",
    "os.chdir(\"C:\\\\Users\\\\25273141\\\\OneDrive - Edge Hill University\\\\Publish\\\\Data\\\\Irish Loan Data\\\\loan\\\\Train\")\n",
    "\n",
    "# reading the df1 csv file from local system\n",
    "df1_train=pd.read_csv(\"df1.csv\", header =0).round(0)\n",
    "df2_train=pd.read_csv(\"df2.csv\", header =0).round(0)\n",
    "df3_train=pd.read_csv(\"df3.csv\", header =0).round(0)\n",
    "df4_train=pd.read_csv(\"df4.csv\", header =0).round(0)\n",
    "df5_train=pd.read_csv(\"df5.csv\", header =0).round(0)\n",
    "df6_train=pd.read_csv(\"df6.csv\", header =0).round(0)\n",
    "\n",
    "# store distributed model prediction outcomes in a dataframe\n",
    "all_distributed_model_train_df1_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_train_df2_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_train_df3_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_train_df4_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_train_df5_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_train_df6_actual_pred=pd.DataFrame()\n",
    "\n",
    "# assign indexes into index column\n",
    "all_distributed_model_train_df1_actual_pred['index']=df1_train.iloc[:,0]\n",
    "all_distributed_model_train_df2_actual_pred['index']=df2_train.iloc[:,0]\n",
    "all_distributed_model_train_df3_actual_pred['index']=df3_train.iloc[:,0]\n",
    "all_distributed_model_train_df4_actual_pred['index']=df4_train.iloc[:,0]\n",
    "all_distributed_model_train_df5_actual_pred['index']=df5_train.iloc[:,0]\n",
    "all_distributed_model_train_df6_actual_pred['index']=df6_train.iloc[:,0]\n",
    "\n",
    "#convert some variables into categoricals\n",
    "cat_numbers = [df1_train.columns.get_loc(col) for col in categorical_columns]\n",
    "for i in cat_numbers:\n",
    "    df1_train.iloc[:,i] = label_encoder.fit_transform(df1_train.iloc[:,i])\n",
    "    df1_train.iloc[:,i] = df1_train.iloc[:,i].astype('category')\n",
    "    \n",
    "for i in cat_numbers:\n",
    "    df2_train.iloc[:,i] = label_encoder.fit_transform(df2_train.iloc[:,i])\n",
    "    df2_train.iloc[:,i] = df2_train.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df3_train.iloc[:,i] = label_encoder.fit_transform(df3_train.iloc[:,i])\n",
    "    df3_train.iloc[:,i] = df3_train.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df4_train.iloc[:,i] = label_encoder.fit_transform(df4_train.iloc[:,i])\n",
    "    df4_train.iloc[:,i] = df4_train.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df5_train.iloc[:,i] = label_encoder.fit_transform(df5_train.iloc[:,i])\n",
    "    df5_train.iloc[:,i] = df5_train.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df6_train.iloc[:,i] = label_encoder.fit_transform(df6_train.iloc[:,i])\n",
    "    df6_train.iloc[:,i] = df6_train.iloc[:,i].astype('category')\n",
    "\n",
    "#set up directory and load files\n",
    "os.chdir(\"C:\\\\Users\\\\25273141\\\\OneDrive - Edge Hill University\\\\Publish\\\\Data\\\\Irish Loan Data\\\\loan\\\\Test\")\n",
    "df1_test=pd.read_csv(\"df1.csv\", header =0).round(0)\n",
    "df2_test=pd.read_csv(\"df2.csv\", header =0).round(0)\n",
    "df3_test=pd.read_csv(\"df3.csv\", header =0).round(0)\n",
    "df4_test=pd.read_csv(\"df4.csv\", header =0).round(0)\n",
    "df5_test=pd.read_csv(\"df5.csv\", header =0).round(0)\n",
    "df6_test=pd.read_csv(\"df6.csv\", header =0).round(0)\n",
    "\n",
    "# create emty dataframes for storing predicted outputs\n",
    "all_distributed_model_test_df1_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_test_df2_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_test_df3_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_test_df4_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_test_df5_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_test_df6_actual_pred=pd.DataFrame()\n",
    "\n",
    "# store indexes into index column\n",
    "all_distributed_model_test_df1_actual_pred['index']=df1_test.iloc[:,0]\n",
    "all_distributed_model_test_df2_actual_pred['index']=df2_test.iloc[:,0]\n",
    "all_distributed_model_test_df3_actual_pred['index']=df3_test.iloc[:,0]\n",
    "all_distributed_model_test_df4_actual_pred['index']=df4_test.iloc[:,0]\n",
    "all_distributed_model_test_df5_actual_pred['index']=df5_test.iloc[:,0]\n",
    "all_distributed_model_test_df6_actual_pred['index']=df6_test.iloc[:,0]\n",
    "\n",
    "#convert some columns into categorical\n",
    "cat_numbers = [df1_test.columns.get_loc(col) for col in categorical_columns]\n",
    "for i in cat_numbers:\n",
    "    df1_test.iloc[:,i] = label_encoder.fit_transform(df1_test.iloc[:,i])\n",
    "    df1_test.iloc[:,i] = df1_test.iloc[:,i].astype('category')\n",
    "    \n",
    "for i in cat_numbers:\n",
    "    df2_test.iloc[:,i] = label_encoder.fit_transform(df2_test.iloc[:,i])\n",
    "    df2_test.iloc[:,i] = df2_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df3_test.iloc[:,i] = label_encoder.fit_transform(df3_test.iloc[:,i])\n",
    "    df3_test.iloc[:,i] = df3_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df4_test.iloc[:,i] = label_encoder.fit_transform(df4_test.iloc[:,i])\n",
    "    df4_test.iloc[:,i] = df4_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df5_test.iloc[:,i] = label_encoder.fit_transform(df5_test.iloc[:,i])\n",
    "    df5_test.iloc[:,i] = df5_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df6_test.iloc[:,i] = label_encoder.fit_transform(df6_test.iloc[:,i])\n",
    "    df6_test.iloc[:,i] = df6_test.iloc[:,i].astype('category')\n",
    "    \n",
    "#combine train and test records\n",
    "df1_train_test=pd.concat([df1_train,df1_test], axis=0, ignore_index=True)\n",
    "df2_train_test=pd.concat([df2_train,df2_test], axis=0, ignore_index=True)\n",
    "df3_train_test=pd.concat([df3_train,df3_test], axis=0, ignore_index=True)\n",
    "df4_train_test=pd.concat([df4_train,df4_test], axis=0, ignore_index=True)\n",
    "df5_train_test=pd.concat([df5_train,df5_test], axis=0, ignore_index=True)\n",
    "df6_train_test=pd.concat([df6_train,df6_test], axis=0, ignore_index=True)\n",
    "\n",
    "#convert some columns into categorical\n",
    "cat_numbers = [df1_train_test.columns.get_loc(col) for col in categorical_columns]\n",
    "for i in cat_numbers:\n",
    "    df1_train_test.iloc[:,i] = label_encoder.fit_transform(df1_train_test.iloc[:,i])\n",
    "    df1_train_test.iloc[:,i] = df1_train_test.iloc[:,i].astype('category')\n",
    "    \n",
    "for i in cat_numbers:\n",
    "    df2_train_test.iloc[:,i] = label_encoder.fit_transform(df2_train_test.iloc[:,i])\n",
    "    df2_train_test.iloc[:,i] = df2_train_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df3_train_test.iloc[:,i] = label_encoder.fit_transform(df3_train_test.iloc[:,i])\n",
    "    df3_train_test.iloc[:,i] = df3_train_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df4_train_test.iloc[:,i] = label_encoder.fit_transform(df4_train_test.iloc[:,i])\n",
    "    df4_train_test.iloc[:,i] = df4_train_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df5_train_test.iloc[:,i] = label_encoder.fit_transform(df5_train_test.iloc[:,i])\n",
    "    df5_train_test.iloc[:,i] = df5_train_test.iloc[:,i].astype('category')\n",
    "\n",
    "for i in cat_numbers:\n",
    "    df6_train_test.iloc[:,i] = label_encoder.fit_transform(df6_train_test.iloc[:,i])\n",
    "    df6_train_test.iloc[:,i] = df6_train_test.iloc[:,i].astype('category')\n",
    "\n",
    "#keep required columns\n",
    "X_train_test_df1=df1_train_test.iloc[:,req_numbers].values\n",
    "y_train_test_df1=df1_train_test.iloc[:,-1].values\n",
    "\n",
    "X_train_test_df2=df2_train_test.iloc[:,req_numbers].values\n",
    "y_train_test_df2=df2_train_test.iloc[:,-1].values\n",
    "\n",
    "X_train_test_df3=df3_train_test.iloc[:,req_numbers].values\n",
    "y_train_test_df3=df3_train_test.iloc[:,-1].values\n",
    "\n",
    "X_train_test_df4=df4_train_test.iloc[:,req_numbers].values\n",
    "y_train_test_df4=df4_train_test.iloc[:,-1].values\n",
    "\n",
    "X_train_test_df5=df5_train_test.iloc[:,req_numbers].values\n",
    "y_train_test_df5=df5_train_test.iloc[:,-1].values\n",
    "\n",
    "X_train_test_df6=df6_train_test.iloc[:,req_numbers].values\n",
    "y_train_test_df6=df6_train_test.iloc[:,-1].values\n",
    "\n",
    "print('df1 total records:', len(df1_train_test))\n",
    "print('df2 total records:', len(df2_train_test))\n",
    "print('df3 total records:', len(df3_train_test))\n",
    "print('df4 total records:', len(df4_train_test))\n",
    "print('df5 total records:', len(df5_train_test))\n",
    "print('df6 total records:', len(df6_train_test))\n",
    "\n",
    "########### train dataset\n",
    "\n",
    "#keep required columns\n",
    "X_train_df1=df1_train.loc[:,required_columns].values\n",
    "y_train_df1=df1_train.iloc[:,-1].values\n",
    "\n",
    "X_train_df2=df2_train.loc[:,required_columns].values\n",
    "y_train_df2=df2_train.iloc[:,-1].values\n",
    "\n",
    "X_train_df3=df3_train.loc[:,required_columns].values\n",
    "y_train_df3=df3_train.iloc[:,-1].values\n",
    "\n",
    "X_train_df4=df4_train.loc[:,required_columns].values\n",
    "y_train_df4=df4_train.iloc[:,-1].values\n",
    "\n",
    "X_train_df5=df5_train.loc[:,required_columns].values\n",
    "y_train_df5=df5_train.iloc[:,-1].values\n",
    "\n",
    "X_train_df6=df6_train.loc[:,required_columns].values\n",
    "y_train_df6=df6_train.iloc[:,-1].values\n",
    "\n",
    "print('df1 total records:', sorted(Counter(y_train_df1).items()), y_train_df1.shape)\n",
    "print('df2 total records:', sorted(Counter(y_train_df2).items()), y_train_df2.shape)\n",
    "print('df3 total records:', sorted(Counter(y_train_df3).items()), y_train_df3.shape)\n",
    "print('df4 total records:', sorted(Counter(y_train_df4).items()), y_train_df4.shape)\n",
    "print('df5 total records:', sorted(Counter(y_train_df5).items()), y_train_df5.shape)\n",
    "print('df6 total records:', sorted(Counter(y_train_df6).items()), y_train_df6.shape)\n",
    "\n",
    "\n",
    "##### test dataset\n",
    "\n",
    "# keep required columns\n",
    "X_test_df1=df1_test.loc[:,required_columns].values\n",
    "y_test_df1=df1_test.iloc[:,-1].values\n",
    "\n",
    "X_test_df2=df2_test.loc[:,required_columns].values\n",
    "y_test_df2=df2_test.iloc[:,-1].values\n",
    "\n",
    "X_test_df3=df3_test.loc[:,required_columns].values\n",
    "y_test_df3=df3_test.iloc[:,-1].values\n",
    "\n",
    "X_test_df4=df4_test.loc[:,required_columns].values\n",
    "y_test_df4=df4_test.iloc[:,-1].values\n",
    "\n",
    "X_test_df5=df5_test.loc[:,required_columns].values\n",
    "y_test_df5=df5_test.iloc[:,-1].values\n",
    "\n",
    "X_test_df6=df6_test.loc[:,required_columns].values\n",
    "y_test_df6=df6_test.iloc[:,-1].values\n",
    "\n",
    "print('df1 total records:', sorted(Counter(y_test_df1).items()), y_test_df1.shape)\n",
    "print('df2 total records:', sorted(Counter(y_test_df2).items()), y_test_df2.shape)\n",
    "print('df3 total records:', sorted(Counter(y_test_df3).items()), y_test_df3.shape)\n",
    "print('df4 total records:', sorted(Counter(y_test_df4).items()), y_test_df4.shape)\n",
    "print('df5 total records:', sorted(Counter(y_test_df5).items()), y_test_df5.shape)\n",
    "print('df6 total records:', sorted(Counter(y_test_df6).items()), y_test_df6.shape)\n",
    "\n",
    "#store actual target labels\n",
    "all_distributed_model_train_df1_actual_pred['actual_flag']=y_train_df1\n",
    "all_distributed_model_train_df2_actual_pred['actual_flag']=y_train_df2\n",
    "all_distributed_model_train_df3_actual_pred['actual_flag']=y_train_df3\n",
    "all_distributed_model_train_df4_actual_pred['actual_flag']=y_train_df4\n",
    "all_distributed_model_train_df5_actual_pred['actual_flag']=y_train_df5\n",
    "all_distributed_model_train_df6_actual_pred['actual_flag']=y_train_df6\n",
    "\n",
    "all_distributed_model_test_df1_actual_pred['actual_flag']=y_test_df1\n",
    "all_distributed_model_test_df2_actual_pred['actual_flag']=y_test_df2\n",
    "all_distributed_model_test_df3_actual_pred['actual_flag']=y_test_df3\n",
    "all_distributed_model_test_df4_actual_pred['actual_flag']=y_test_df4\n",
    "all_distributed_model_test_df5_actual_pred['actual_flag']=y_test_df5\n",
    "all_distributed_model_test_df6_actual_pred['actual_flag']=y_test_df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e232aac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 total records: [(0, 160770), (1, 13198)] (173968,)\n",
      "df2 total records: [(0, 54297), (1, 45959)] (100256,)\n",
      "df3 total records: [(0, 56872), (1, 50387)] (107259,)\n",
      "df4 total records: [(0, 50980), (1, 45106)] (96086,)\n",
      "df5 total records: [(0, 51747), (1, 45260)] (97007,)\n",
      "df6 total records: [(0, 54679), (1, 48221)] (102900,)\n"
     ]
    }
   ],
   "source": [
    "# setting up working directory\n",
    "os.chdir(\"C:\\\\Users\\\\25273141\\\\OneDrive - Edge Hill University\\\\Publish\\\\Data\\\\Irish Loan Data\\\\loan\\\\eval\")\n",
    "\n",
    "# reading the df1 csv file from local system\n",
    "df1_eval=pd.read_csv(\"df1.csv\", header =0).round(0)\n",
    "req_numbers = [df1_eval.columns.get_loc(col) for col in required_columns]\n",
    "\n",
    "#keep required columsns\n",
    "X_eval_df1=df1_eval.loc[:,required_columns]\n",
    "y_eval_df1=df1_eval.iloc[:,-1]\n",
    "\n",
    "# reading the df2 csv file from local system\n",
    "df2_eval=pd.read_csv(\"df2.csv\", header =0).round(0)\n",
    "X_eval_df2=df2_eval.loc[:,required_columns]\n",
    "y_eval_df2=df2_eval.iloc[:,-1]\n",
    "\n",
    "# reading the df3 csv file from local system\n",
    "df3_eval=pd.read_csv(\"df3.csv\", header =0).round(0)\n",
    "X_eval_df3=df3_eval.loc[:,required_columns]\n",
    "y_eval_df3=df3_eval.iloc[:,-1]\n",
    "\n",
    "# reading the df4 csv file from local system\n",
    "df4_eval=pd.read_csv(\"df4.csv\", header =0).round(0)\n",
    "X_eval_df4=df4_eval.loc[:,required_columns]\n",
    "y_eval_df4=df4_eval.iloc[:,-1]\n",
    "\n",
    "# reading the df5 csv file from local system\n",
    "df5_eval=pd.read_csv(\"df5.csv\", header =0).round(0)\n",
    "X_eval_df5=df5_eval.loc[:,required_columns]\n",
    "y_eval_df5=df5_eval.iloc[:,-1]\n",
    "\n",
    "# reading the df6 csv file from local system\n",
    "df6_eval=pd.read_csv(\"df6.csv\", header =0).round(0)\n",
    "X_eval_df6=df6_eval.loc[:,required_columns]\n",
    "y_eval_df6=df6_eval.iloc[:,-1]\n",
    "   \n",
    "print('df1 total records:', sorted(Counter(y_eval_df1).items()), y_eval_df1.shape)\n",
    "print('df2 total records:', sorted(Counter(y_eval_df2).items()), y_eval_df2.shape)\n",
    "print('df3 total records:', sorted(Counter(y_eval_df3).items()), y_eval_df3.shape)\n",
    "print('df4 total records:', sorted(Counter(y_eval_df4).items()), y_eval_df4.shape)\n",
    "print('df5 total records:', sorted(Counter(y_eval_df5).items()), y_eval_df5.shape)\n",
    "print('df6 total records:', sorted(Counter(y_eval_df6).items()), y_eval_df6.shape)\n",
    "\n",
    "#create dataframe for storing predicted labels\n",
    "all_distributed_model_eval_df1_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_eval_df2_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_eval_df3_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_eval_df4_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_eval_df5_actual_pred=pd.DataFrame()\n",
    "all_distributed_model_eval_df6_actual_pred=pd.DataFrame()\n",
    "\n",
    "#add indexes into index column\n",
    "all_distributed_model_eval_df1_actual_pred['index']=df1_eval.iloc[:,0]\n",
    "all_distributed_model_eval_df2_actual_pred['index']=df2_eval.iloc[:,0]\n",
    "all_distributed_model_eval_df3_actual_pred['index']=df3_eval.iloc[:,0]\n",
    "all_distributed_model_eval_df4_actual_pred['index']=df4_eval.iloc[:,0]\n",
    "all_distributed_model_eval_df5_actual_pred['index']=df5_eval.iloc[:,0]\n",
    "all_distributed_model_eval_df6_actual_pred['index']=df6_eval.iloc[:,0]\n",
    "\n",
    "# add actual flags into dataframe \n",
    "all_distributed_model_eval_df1_actual_pred['actual_flag']=y_eval_df1\n",
    "all_distributed_model_eval_df2_actual_pred['actual_flag']=y_eval_df2\n",
    "all_distributed_model_eval_df3_actual_pred['actual_flag']=y_eval_df3\n",
    "all_distributed_model_eval_df4_actual_pred['actual_flag']=y_eval_df4\n",
    "all_distributed_model_eval_df5_actual_pred['actual_flag']=y_eval_df5\n",
    "all_distributed_model_eval_df6_actual_pred['actual_flag']=y_eval_df6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c0cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------single LR model train dataset performance--------------------------\n",
      "[[1584554  871884]\n",
      " [ 132826  120639]]\n",
      "Accuracy, precision,sensitivity, recall, F1_score for train data by LR model are the following: [0.63 0.65 0.92 0.12 0.76]\n",
      "-------------------------single LR model evaluation dataset performance--------------------------\n",
      "[[396095 218109]\n",
      " [ 33250  30022]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for eval data by LR model are the following: [0.63 0.64 0.92 0.12 0.76]\n",
      "time taken for the Single LR model to run and produce outcomes: 0:00:19.947148\n"
     ]
    }
   ],
   "source": [
    "# import datetime library\n",
    "import datetime\n",
    "\n",
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# import Logistic Regression library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "# Build a Logistic Regression Classifier\n",
    "\n",
    "LR_model = LogisticRegression()\n",
    "\n",
    "# passing the train independent metrics with dependent variable to the decision tree model\n",
    "LR_model.fit(X_raw_train, y_raw_train)\n",
    "\n",
    "# store actual and prediction outcomes\n",
    "all_single_model_raw_train_actual_pred['actual_flag']= y_train\n",
    "all_single_model_raw_train_actual_pred['LR_model_pred']= LR_model.predict(X_train)\n",
    "all_single_model_raw_test_actual_pred['actual_flag']= y_test\n",
    "all_single_model_raw_test_actual_pred['LR_model_pred']= LR_model.predict(X_test)\n",
    "all_single_model_raw_eval_actual_pred['actual_flag']= y_raw_eval\n",
    "all_single_model_raw_eval_actual_pred['LR_model_pred']= LR_model.predict(X_raw_eval)\n",
    "\n",
    "# Evaluate the train dataset \n",
    "print('-------------------------single LR model train dataset performance--------------------------')\n",
    "conf_matrix_LR_train=confusion_matrix(LR_model.predict(X_raw_train),y_raw_train)\n",
    "LR_train_final_accuracy = (conf_matrix_LR_train[0, 0] + conf_matrix_LR_train[1, 1]) / np.sum(conf_matrix_LR_train)\n",
    "LR_train_final_precision = conf_matrix_LR_train[0, 0] / (conf_matrix_LR_train[0, 0] + conf_matrix_LR_train[0, 1])\n",
    "LR_train_final_sensitivity = conf_matrix_LR_train[0, 0] / (conf_matrix_LR_train[0, 0] + conf_matrix_LR_train[1, 0])\n",
    "LR_train_final_recall = conf_matrix_LR_train[1, 1] / (conf_matrix_LR_train[1, 1] + conf_matrix_LR_train[0, 1])\n",
    "LR_train_final_f1 = (2*conf_matrix_LR_train[0, 0])/ ((2*conf_matrix_LR_train[0, 0])+conf_matrix_LR_train[1, 0]+conf_matrix_LR_train[0, 1])\n",
    "\n",
    "LR_train_perf=[np.round(LR_train_final_accuracy,2),np.round(LR_train_final_precision,2),np.round(LR_train_final_sensitivity,2), np.round(LR_train_final_recall,2),np.round(LR_train_final_f1,2)]\n",
    "\n",
    "print(conf_matrix_LR_train)\n",
    "print('Accuracy, precision,sensitivity, recall, F1_score for train data by LR model are the following:',np.round(LR_train_perf,2))\n",
    "\n",
    "# Evaluate the test dataset \n",
    "print('-------------------------single LR model evaluation dataset performance--------------------------')\n",
    "\n",
    "conf_matrix_LR_eval=confusion_matrix(LR_model.predict(X_raw_eval), y_raw_eval)\n",
    "LR_eval_final_accuracy = (conf_matrix_LR_eval[0, 0] + conf_matrix_LR_eval[1, 1]) / np.sum(conf_matrix_LR_eval)\n",
    "LR_eval_final_precision = conf_matrix_LR_eval[0, 0] / (conf_matrix_LR_eval[0, 0] + conf_matrix_LR_eval[0, 1])\n",
    "LR_eval_final_sensitivity = conf_matrix_LR_eval[0, 0] / (conf_matrix_LR_eval[0, 0] + conf_matrix_LR_eval[1, 0])\n",
    "LR_eval_final_recall = conf_matrix_LR_eval[1, 1] / (conf_matrix_LR_eval[1, 1] + conf_matrix_LR_eval[0, 1])\n",
    "LR_eval_final_f1 = (2*conf_matrix_LR_eval[0, 0])/ ((2*conf_matrix_LR_eval[0, 0])+conf_matrix_LR_eval[1, 0]+conf_matrix_LR_eval[0, 1])\n",
    "\n",
    "LR_eval_perf=[np.round(LR_eval_final_accuracy,2),np.round(LR_eval_final_precision,2),np.round(LR_eval_final_sensitivity,2),np.round(LR_eval_final_recall,2),np.round(LR_eval_final_f1,2)]\n",
    "\n",
    "print(conf_matrix_LR_eval)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for eval data by LR model are the following:',np.round(LR_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the Single LR model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab63ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1219221  544984]\n",
      " [  90399   74976]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for hexa-distributed train data by same LR models are the following: [0.67 0.69 0.93 0.12 0.79]\n",
      "[[375168 201278]\n",
      " [ 54177  46853]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for hexa-distributed eval data by same LR models are the following: [0.62 0.65 0.87 0.19 0.75]\n",
      "time taken for the hexa-distributed system using LR model to run and produce outcomes: 0:00:13.163537\n"
     ]
    }
   ],
   "source": [
    "# delete Logitic Regression model confusion matrix variables\n",
    "del conf_matrix_LR_train,conf_matrix_LR_eval\n",
    "\n",
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Create 6 Logistic Regression datasets\n",
    "train_df1_LR = X_train_test_df1\n",
    "eval_df1_LR = X_eval_df1\n",
    "train_df2_LR = X_train_test_df2\n",
    "eval_df2_LR = X_eval_df2\n",
    "train_df3_LR = X_train_test_df3\n",
    "eval_df3_LR = X_eval_df3\n",
    "train_df4_LR = X_train_test_df4\n",
    "eval_df4_LR = X_eval_df4\n",
    "train_df5_LR = X_train_test_df5\n",
    "eval_df5_LR = X_eval_df5\n",
    "train_df6_LR = X_train_test_df6\n",
    "eval_df6_LR = X_eval_df6\n",
    "\n",
    "# build the Logistic Regression models \n",
    "LR_df1 = LogisticRegression()\n",
    "LR_df1.fit(train_df1_LR, y_train_test_df1)\n",
    "LR_df2 = LogisticRegression()\n",
    "LR_df2.fit(train_df2_LR, y_train_test_df2)\n",
    "LR_df3 = LogisticRegression()\n",
    "LR_df3.fit(train_df3_LR, y_train_test_df3)\n",
    "LR_df4 = LogisticRegression()\n",
    "LR_df4.fit(train_df4_LR, y_train_test_df4)\n",
    "LR_df5 =LogisticRegression()\n",
    "LR_df5.fit(train_df5_LR, y_train_test_df5)\n",
    "LR_df6 = LogisticRegression()\n",
    "LR_df6.fit(train_df6_LR, y_train_test_df6)\n",
    "\n",
    "#store actual and predicted labels\n",
    "all_distributed_model_train_df1_actual_pred['LR_model_pred']=LR_df1.predict(X_train_df1)\n",
    "all_distributed_model_train_df2_actual_pred['LR_model_pred']=LR_df2.predict(X_train_df2)\n",
    "all_distributed_model_train_df3_actual_pred['LR_model_pred']=LR_df3.predict(X_train_df3)\n",
    "all_distributed_model_train_df4_actual_pred['LR_model_pred']=LR_df4.predict(X_train_df4)\n",
    "all_distributed_model_train_df5_actual_pred['LR_model_pred']=LR_df5.predict(X_train_df5)\n",
    "all_distributed_model_train_df6_actual_pred['LR_model_pred']=LR_df6.predict(X_train_df6)\n",
    "\n",
    "all_distributed_model_test_df1_actual_pred['LR_model_pred']=LR_df1.predict(X_test_df1)\n",
    "all_distributed_model_test_df2_actual_pred['LR_model_pred']=LR_df2.predict(X_test_df2)\n",
    "all_distributed_model_test_df3_actual_pred['LR_model_pred']=LR_df3.predict(X_test_df3)\n",
    "all_distributed_model_test_df4_actual_pred['LR_model_pred']=LR_df4.predict(X_test_df4)\n",
    "all_distributed_model_test_df5_actual_pred['LR_model_pred']=LR_df5.predict(X_test_df5)\n",
    "all_distributed_model_test_df6_actual_pred['LR_model_pred']=LR_df6.predict(X_test_df6)\n",
    "\n",
    "all_distributed_model_eval_df1_actual_pred['LR_model_pred']=LR_df1.predict(X_eval_df1)\n",
    "all_distributed_model_eval_df2_actual_pred['LR_model_pred']=LR_df2.predict(X_eval_df2)\n",
    "all_distributed_model_eval_df3_actual_pred['LR_model_pred']=LR_df3.predict(X_eval_df3)\n",
    "all_distributed_model_eval_df4_actual_pred['LR_model_pred']=LR_df4.predict(X_eval_df4)\n",
    "all_distributed_model_eval_df5_actual_pred['LR_model_pred']=LR_df5.predict(X_eval_df5)\n",
    "all_distributed_model_eval_df6_actual_pred['LR_model_pred']=LR_df6.predict(X_eval_df6)\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 LR models for training dataset\n",
    "LR_train_1 = confusion_matrix(np.round(LR_df1.predict(train_df1_LR)),y_train_test_df1)\n",
    "LR_train_2 = confusion_matrix(np.round(LR_df2.predict(train_df2_LR)),y_train_test_df2)\n",
    "LR_train_3 = confusion_matrix(np.round(LR_df3.predict(train_df3_LR)),y_train_test_df3)\n",
    "LR_train_4 = confusion_matrix(np.round(LR_df4.predict(train_df4_LR)),y_train_test_df4)\n",
    "LR_train_5 = confusion_matrix(np.round(LR_df5.predict(train_df5_LR)),y_train_test_df5)\n",
    "LR_train_6 = confusion_matrix(np.round(LR_df6.predict(train_df6_LR)),y_train_test_df6)\n",
    "conf_matrix_LR_train=LR_train_1 +LR_train_2 + LR_train_3 + LR_train_4 + LR_train_5 +LR_train_6\n",
    "LR_train_final_accuracy = (conf_matrix_LR_train[0, 0] + conf_matrix_LR_train[1, 1]) / np.sum(conf_matrix_LR_train)\n",
    "LR_train_final_precision = conf_matrix_LR_train[0, 0] / (conf_matrix_LR_train[0, 0] + conf_matrix_LR_train[0, 1])\n",
    "LR_train_final_sensitivity = conf_matrix_LR_train[0, 0] / (conf_matrix_LR_train[0, 0] + conf_matrix_LR_train[1, 0])\n",
    "LR_train_final_recall = conf_matrix_LR_train[1, 1] / (conf_matrix_LR_train[1, 1] + conf_matrix_LR_train[0, 1])\n",
    "LR_train_final_f1 = (2*conf_matrix_LR_train[0, 0])/ ((2*conf_matrix_LR_train[0, 0])+conf_matrix_LR_train[1, 0]+conf_matrix_LR_train[0, 1])\n",
    "LR_train_perf=[np.round(LR_train_final_accuracy,2),np.round(LR_train_final_precision,2),np.round(LR_train_final_sensitivity,2), np.round(LR_train_final_recall,2),np.round(LR_train_final_f1,2)]\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 LR models for evaluation dataset\n",
    "LR_eval_1 = confusion_matrix(np.round(LR_df1.predict(eval_df1_LR)),y_eval_df1)\n",
    "LR_eval_2 = confusion_matrix(np.round(LR_df2.predict(eval_df2_LR)),y_eval_df2)\n",
    "LR_eval_3 = confusion_matrix(np.round(LR_df3.predict(eval_df3_LR)),y_eval_df3)\n",
    "LR_eval_4 = confusion_matrix(np.round(LR_df4.predict(eval_df4_LR)),y_eval_df4)\n",
    "LR_eval_5 = confusion_matrix(np.round(LR_df5.predict(eval_df5_LR)),y_eval_df5)\n",
    "LR_eval_6 = confusion_matrix(np.round(LR_df6.predict(eval_df6_LR)),y_eval_df6)\n",
    "conf_matrix_LR_eval=LR_eval_1 +LR_eval_2 + LR_eval_3 + LR_eval_4 + LR_eval_5 +LR_eval_6\n",
    "LR_eval_final_accuracy = (conf_matrix_LR_eval[0, 0] + conf_matrix_LR_eval[1, 1]) / np.sum(conf_matrix_LR_eval)\n",
    "LR_eval_final_precision = conf_matrix_LR_eval[0, 0] / (conf_matrix_LR_eval[0, 0] + conf_matrix_LR_eval[0, 1])\n",
    "LR_eval_final_sensitivity = conf_matrix_LR_eval[0, 0] / (conf_matrix_LR_eval[0, 0] + conf_matrix_LR_eval[1, 0])\n",
    "LR_eval_final_recall = conf_matrix_LR_eval[1, 1] / (conf_matrix_LR_eval[1, 1] + conf_matrix_LR_eval[0, 1])\n",
    "LR_eval_final_f1 = (2*conf_matrix_LR_eval[0, 0])/ ((2*conf_matrix_LR_eval[0, 0])+conf_matrix_LR_eval[1, 0]+conf_matrix_LR_eval[0, 1])\n",
    "LR_eval_perf=[np.round(LR_eval_final_accuracy,2),np.round(LR_eval_final_precision,2),np.round(LR_eval_final_sensitivity,2),np.round(LR_eval_final_recall,2),np.round(LR_eval_final_f1,2)]\n",
    "\n",
    "# print('--------------------------performance--------------------------------------------')\n",
    "print(conf_matrix_LR_train)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for hexa-distributed train data by same LR models are the following:',np.round(LR_train_perf,2))\n",
    "print(conf_matrix_LR_eval)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for hexa-distributed eval data by same LR models are the following:',np.round(LR_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the hexa-distributed system using LR model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f1bca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 794018, number of negative: 1373904\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1699\n",
      "[LightGBM] [Info] Number of data points in the train set: 2167922, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.366258 -> initscore=-0.548305\n",
      "[LightGBM] [Info] Start training from score -0.548305\n",
      "-------------------------single LGB model train dataset performance--------------------------\n",
      "[[1717357  981620]\n",
      " [     23   10903]]\n",
      "Accuracy, precision,sensitivity, recall, F1_score for train data by LGB model are the following: [0.64 0.64 1.   0.01 0.78]\n",
      "-------------------------single LGB model evaluation dataset performance--------------------------\n",
      "[[429343 245426]\n",
      " [     2   2705]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for eval data by LGB model are the following: [0.64 0.64 1.   0.01 0.78]\n",
      "time taken for the Single LGB model to run and produce outcomes: 0:00:12.720384\n"
     ]
    }
   ],
   "source": [
    "# import datetime library\n",
    "import datetime\n",
    "\n",
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# import light gbm library\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Create a LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "eval_data = lgb.Dataset(X_raw_eval)\n",
    "\n",
    "# Set parameters for the LightGBM model\n",
    "params = {\n",
    "    \"objective\": \"binary\",    # for binary classification\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"feature_fraction\": 0.9\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "num_round =38\n",
    "\n",
    "LGB_model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "# store actual and prediction outcomes\n",
    "all_single_model_raw_train_actual_pred['LGB_model_pred']= np.round(LGB_model.predict(X_train, num_iteration=LGB_model.best_iteration))\n",
    "all_single_model_raw_test_actual_pred['LGB_model_pred']= np.round(LGB_model.predict(X_test, num_iteration=LGB_model.best_iteration))\n",
    "all_single_model_raw_eval_actual_pred['LGB_model_pred']= np.round(LGB_model.predict(X_raw_eval, num_iteration=LGB_model.best_iteration))\n",
    "\n",
    "# Evaluate the train dataset \n",
    "print('-------------------------single LGB model train dataset performance--------------------------')\n",
    "conf_matrix_LGB_train=confusion_matrix(np.round(LGB_model.predict(X_raw_train, num_iteration=LGB_model.best_iteration)),y_raw_train)\n",
    "LGB_train_final_accuracy = (conf_matrix_LGB_train[0, 0] + conf_matrix_LGB_train[1, 1]) / np.sum(conf_matrix_LGB_train)\n",
    "LGB_train_final_precision = conf_matrix_LGB_train[0, 0] / (conf_matrix_LGB_train[0, 0] + conf_matrix_LGB_train[0, 1])\n",
    "LGB_train_final_sensitivity = conf_matrix_LGB_train[0, 0] / (conf_matrix_LGB_train[0, 0] + conf_matrix_LGB_train[1, 0])\n",
    "LGB_train_final_recall = conf_matrix_LGB_train[1, 1] / (conf_matrix_LGB_train[1, 1] + conf_matrix_LGB_train[0, 1])\n",
    "LGB_train_final_f1 = (2*conf_matrix_LGB_train[0, 0])/ ((2*conf_matrix_LGB_train[0, 0])+conf_matrix_LGB_train[1, 0]+conf_matrix_LGB_train[0, 1])\n",
    "LGB_train_perf=[np.round(LGB_train_final_accuracy,2),np.round(LGB_train_final_precision,2),np.round(LGB_train_final_sensitivity,2), np.round(LGB_train_final_recall,2),np.round(LGB_train_final_f1,2)]\n",
    "\n",
    "print(conf_matrix_LGB_train)\n",
    "print('Accuracy, precision,sensitivity, recall, F1_score for train data by LGB model are the following:',np.round(LGB_train_perf,2))\n",
    "\n",
    "# Evaluate the test dataset \n",
    "print('-------------------------single LGB model evaluation dataset performance--------------------------')\n",
    "conf_matrix_LGB_eval=confusion_matrix(np.round(LGB_model.predict(X_raw_eval, num_iteration=LGB_model.best_iteration)), y_raw_eval)\n",
    "LGB_eval_final_accuracy = (conf_matrix_LGB_eval[0, 0] + conf_matrix_LGB_eval[1, 1]) / np.sum(conf_matrix_LGB_eval)\n",
    "LGB_eval_final_precision = conf_matrix_LGB_eval[0, 0] / (conf_matrix_LGB_eval[0, 0] + conf_matrix_LGB_eval[0, 1])\n",
    "LGB_eval_final_sensitivity = conf_matrix_LGB_eval[0, 0] / (conf_matrix_LGB_eval[0, 0] + conf_matrix_LGB_eval[1, 0])\n",
    "LGB_eval_final_recall = conf_matrix_LGB_eval[1, 1] / (conf_matrix_LGB_eval[1, 1] + conf_matrix_LGB_eval[0, 1])\n",
    "LGB_eval_final_f1 = (2*conf_matrix_LGB_eval[0, 0])/ ((2*conf_matrix_LGB_eval[0, 0])+conf_matrix_LGB_eval[1, 0]+conf_matrix_LGB_eval[0, 1])\n",
    "LGB_eval_perf=[np.round(LGB_eval_final_accuracy,2),np.round(LGB_eval_final_precision,2),np.round(LGB_eval_final_sensitivity,2),np.round(LGB_eval_final_recall,2),np.round(LGB_eval_final_f1,2)]\n",
    "print(conf_matrix_LGB_eval)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for eval data by LGB model are the following:',np.round(LGB_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the Single LGB model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb976804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 108468, number of negative: 248764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1690\n",
      "[LightGBM] [Info] Number of data points in the train set: 357232, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.303635 -> initscore=-0.830049\n",
      "[LightGBM] [Info] Start training from score -0.830049\n",
      "[LightGBM] [Info] Number of positive: 61244, number of negative: 140480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1691\n",
      "[LightGBM] [Info] Number of data points in the train set: 201724, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.303603 -> initscore=-0.830199\n",
      "[LightGBM] [Info] Start training from score -0.830199\n",
      "[LightGBM] [Info] Number of positive: 66722, number of negative: 152227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 218949, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.304738 -> initscore=-0.824838\n",
      "[LightGBM] [Info] Start training from score -0.824838\n",
      "[LightGBM] [Info] Number of positive: 59112, number of negative: 136380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 195492, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302376 -> initscore=-0.836011\n",
      "[LightGBM] [Info] Start training from score -0.836011\n",
      "[LightGBM] [Info] Number of positive: 60712, number of negative: 139288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.303560 -> initscore=-0.830402\n",
      "[LightGBM] [Info] Start training from score -0.830402\n",
      "[LightGBM] [Info] Number of positive: 65197, number of negative: 149005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 214202, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.304372 -> initscore=-0.826566\n",
      "[LightGBM] [Info] Start training from score -0.826566\n",
      "[[429345 246141]\n",
      " [     0   1990]]\n",
      "[[949199 508601]\n",
      " [360421 111359]]\n",
      "Accuracy, precision, sensitivity,recall, F1_score for hexa-distributed train_test data by same LGB models are the following: [0.55 0.65 0.72 0.18 0.69]\n",
      "[[429345 246141]\n",
      " [     0   1990]]\n",
      "Accuracy, precision, sensitivity,recall, F1_score, for hexa-distributed eval data by same LGB models are the following: [0.64 0.64 1.   0.01 0.78]\n",
      "time taken for the hexa-distributed system using LGB model to run and produce outcomes: 0:00:06.909309\n"
     ]
    }
   ],
   "source": [
    "# delete LGB model confusion matrix variables\n",
    "del conf_matrix_LGB_train,conf_matrix_LGB_eval\n",
    "# import datetime library\n",
    "import datetime\n",
    "\n",
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "#import light gbm library\n",
    "import lightgbm as LGB\n",
    "\n",
    "# Create a LightGBM dataset\n",
    "train_df1_LGB = LGB.Dataset(X_train_df1, label=y_train_df1)\n",
    "test_df1_LGB = LGB.Dataset(X_test_df1, label=y_test_df1, reference=train_df1_LGB)\n",
    "train_df2_LGB = LGB.Dataset(X_train_df2, label=y_train_df2)\n",
    "test_df2_LGB = LGB.Dataset(X_test_df2, label=y_test_df2, reference=train_df2_LGB)\n",
    "train_df3_LGB = LGB.Dataset(X_train_df3, label=y_train_df3)\n",
    "test_df3_LGB = LGB.Dataset(X_test_df3, label=y_test_df3, reference=train_df3_LGB)\n",
    "train_df4_LGB = LGB.Dataset(X_train_df4, label=y_train_df4)\n",
    "test_df4_LGB = LGB.Dataset(X_test_df4, label=y_test_df4, reference=train_df4_LGB)\n",
    "train_df5_LGB = LGB.Dataset(X_train_df5, label=y_train_df5)\n",
    "test_df5_LGB = LGB.Dataset(X_test_df5, label=y_test_df5, reference=train_df5_LGB)\n",
    "train_df6_LGB = LGB.Dataset(X_train_df6, label=y_train_df6)\n",
    "test_df6_LGB = LGB.Dataset(X_test_df6, label=y_test_df6, reference=train_df6_LGB)\n",
    "\n",
    "# Set parameters for the LightGBM model\n",
    "params = {\n",
    "    \"objective\": \"binary\",    # for binary classification\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"feature_fraction\": 0.9\n",
    "}\n",
    "\n",
    "\n",
    "# Train the LightGBM model\n",
    "LGB_df1 = LGB.train(params, train_df1_LGB, 51, valid_sets=[test_df1_LGB])\n",
    "LGB_df2 = LGB.train(params, train_df2_LGB, 1, valid_sets=[test_df2_LGB])\n",
    "LGB_df3 = LGB.train(params, train_df3_LGB, 1, valid_sets=[test_df3_LGB])\n",
    "LGB_df4 = LGB.train(params, train_df4_LGB, 1, valid_sets=[test_df4_LGB])\n",
    "LGB_df5 = LGB.train(params, train_df5_LGB, 1, valid_sets=[test_df5_LGB])\n",
    "LGB_df6 = LGB.train(params, train_df6_LGB, 1, valid_sets=[test_df6_LGB])\n",
    "\n",
    "#store actual and predicted labels\n",
    "all_distributed_model_train_df1_actual_pred['LGB_model_pred']=np.round(LGB_df1.predict(X_train_df1, num_iteration=LGB_df1.best_iteration))\n",
    "all_distributed_model_train_df2_actual_pred['LGB_model_pred']=np.round(LGB_df2.predict(X_train_df2, num_iteration=LGB_df2.best_iteration))\n",
    "all_distributed_model_train_df3_actual_pred['LGB_model_pred']=np.round(LGB_df3.predict(X_train_df3, num_iteration=LGB_df3.best_iteration))\n",
    "all_distributed_model_train_df4_actual_pred['LGB_model_pred']=np.round(LGB_df4.predict(X_train_df4, num_iteration=LGB_df4.best_iteration))\n",
    "all_distributed_model_train_df5_actual_pred['LGB_model_pred']=np.round(LGB_df5.predict(X_train_df5, num_iteration=LGB_df5.best_iteration))\n",
    "all_distributed_model_train_df6_actual_pred['LGB_model_pred']=np.round(LGB_df6.predict(X_train_df6, num_iteration=LGB_df6.best_iteration))\n",
    "\n",
    "all_distributed_model_test_df1_actual_pred['LGB_model_pred']=np.round(LGB_df1.predict(X_test_df1, num_iteration=LGB_df1.best_iteration))\n",
    "all_distributed_model_test_df2_actual_pred['LGB_model_pred']=np.round(LGB_df2.predict(X_test_df2, num_iteration=LGB_df2.best_iteration))\n",
    "all_distributed_model_test_df3_actual_pred['LGB_model_pred']=np.round(LGB_df3.predict(X_test_df3, num_iteration=LGB_df3.best_iteration))\n",
    "all_distributed_model_test_df4_actual_pred['LGB_model_pred']=np.round(LGB_df4.predict(X_test_df4, num_iteration=LGB_df4.best_iteration))\n",
    "all_distributed_model_test_df5_actual_pred['LGB_model_pred']=np.round(LGB_df5.predict(X_test_df5, num_iteration=LGB_df5.best_iteration))\n",
    "all_distributed_model_test_df6_actual_pred['LGB_model_pred']=np.round(LGB_df6.predict(X_test_df6, num_iteration=LGB_df6.best_iteration))\n",
    "\n",
    "all_distributed_model_eval_df1_actual_pred['LGB_model_pred']=np.round(LGB_df1.predict(X_eval_df1, num_iteration=LGB_df1.best_iteration))\n",
    "all_distributed_model_eval_df2_actual_pred['LGB_model_pred']=np.round(LGB_df2.predict(X_eval_df2, num_iteration=LGB_df2.best_iteration))\n",
    "all_distributed_model_eval_df3_actual_pred['LGB_model_pred']=np.round(LGB_df3.predict(X_eval_df3, num_iteration=LGB_df3.best_iteration))\n",
    "all_distributed_model_eval_df4_actual_pred['LGB_model_pred']=np.round(LGB_df4.predict(X_eval_df4, num_iteration=LGB_df4.best_iteration))\n",
    "all_distributed_model_eval_df5_actual_pred['LGB_model_pred']=np.round(LGB_df5.predict(X_eval_df5, num_iteration=LGB_df5.best_iteration))\n",
    "all_distributed_model_eval_df6_actual_pred['LGB_model_pred']=np.round(LGB_df6.predict(X_eval_df6, num_iteration=LGB_df6.best_iteration))\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score, and auc score  by taking average of 6 LGB models  for training dataset\n",
    "LGB_train_1 = confusion_matrix(np.round(LGB_df1.predict(X_train_test_df1, num_iteration=LGB_df1.best_iteration)),y_train_test_df1)\n",
    "LGB_train_2 = confusion_matrix(np.round(LGB_df2.predict(X_train_test_df2, num_iteration=LGB_df2.best_iteration)),y_train_test_df2)\n",
    "LGB_train_3 = confusion_matrix(np.round(LGB_df3.predict(X_train_test_df3, num_iteration=LGB_df3.best_iteration)),y_train_test_df3)\n",
    "LGB_train_4 = confusion_matrix(np.round(LGB_df4.predict(X_train_test_df4, num_iteration=LGB_df4.best_iteration)),y_train_test_df4)\n",
    "LGB_train_5 = confusion_matrix(np.round(LGB_df5.predict(X_train_test_df5, num_iteration=LGB_df5.best_iteration)),y_train_test_df5)\n",
    "LGB_train_6 = confusion_matrix(np.round(LGB_df6.predict(X_train_test_df6, num_iteration=LGB_df6.best_iteration)),y_train_test_df6)\n",
    "conf_matrix_LGB_train=LGB_train_1 +LGB_train_2 + LGB_train_3 + LGB_train_4 + LGB_train_5 +LGB_train_6\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score, and auc score  by taking average of 6 LGB models for evaluation dataset\n",
    "LGB_eval_1 = confusion_matrix(np.round(LGB_df1.predict(X_eval_df1, num_iteration=LGB_df1.best_iteration)),y_eval_df1)\n",
    "LGB_eval_2 = confusion_matrix(np.round(LGB_df2.predict(X_eval_df2, num_iteration=LGB_df2.best_iteration)),y_eval_df2)\n",
    "LGB_eval_3 = confusion_matrix(np.round(LGB_df3.predict(X_eval_df3, num_iteration=LGB_df3.best_iteration)),y_eval_df3)\n",
    "LGB_eval_4 = confusion_matrix(np.round(LGB_df4.predict(X_eval_df4, num_iteration=LGB_df4.best_iteration)),y_eval_df4)\n",
    "LGB_eval_5 = confusion_matrix(np.round(LGB_df5.predict(X_eval_df5, num_iteration=LGB_df5.best_iteration)),y_eval_df5)\n",
    "LGB_eval_6 = confusion_matrix(np.round(LGB_df6.predict(X_eval_df6, num_iteration=LGB_df6.best_iteration)),y_eval_df6)\n",
    "conf_matrix_LGB_eval=LGB_eval_1 +LGB_eval_2 + LGB_eval_3 + LGB_eval_4 + LGB_eval_5 +LGB_eval_6\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 LGB models for train dataset\n",
    "LGB_train_final_accuracy = (conf_matrix_LGB_train[0, 0] + conf_matrix_LGB_train[1, 1]) / np.sum(conf_matrix_LGB_train)\n",
    "LGB_train_final_precision = conf_matrix_LGB_train[0, 0] / (conf_matrix_LGB_train[0, 0] + conf_matrix_LGB_train[0, 1])\n",
    "LGB_train_final_sensitivity = conf_matrix_LGB_train[0, 0] / (conf_matrix_LGB_train[0, 0] + conf_matrix_LGB_train[1, 0])\n",
    "LGB_train_final_recall = conf_matrix_LGB_train[1, 1] / (conf_matrix_LGB_train[1, 1] + conf_matrix_LGB_train[0, 1])\n",
    "LGB_train_final_f1 = (2*conf_matrix_LGB_train[0, 0])/ ((2*conf_matrix_LGB_train[0, 0])+conf_matrix_LGB_train[1, 0]+conf_matrix_LGB_train[0, 1])\n",
    "LGB_train_test_perf=[np.round(LGB_train_final_accuracy,2),np.round(LGB_train_final_precision,2),np.round(LGB_train_final_sensitivity,2), np.round(LGB_train_final_recall,2),np.round(LGB_train_final_f1,2)]\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 LGB models for test dataset\n",
    "LGB_eval_final_accuracy = (conf_matrix_LGB_eval[0, 0] + conf_matrix_LGB_eval[1, 1]) / np.sum(conf_matrix_LGB_eval)\n",
    "LGB_eval_final_precision = conf_matrix_LGB_eval[0, 0] / (conf_matrix_LGB_eval[0, 0] + conf_matrix_LGB_eval[0, 1])\n",
    "LGB_eval_final_sensitivity = conf_matrix_LGB_eval[0, 0] / (conf_matrix_LGB_eval[0, 0] + conf_matrix_LGB_eval[1, 0])\n",
    "LGB_eval_final_recall = conf_matrix_LGB_eval[1, 1] / (conf_matrix_LGB_eval[1, 1] + conf_matrix_LGB_eval[0, 1])\n",
    "LGB_eval_final_f1 = (2*conf_matrix_LGB_eval[0, 0])/ ((2*conf_matrix_LGB_eval[0, 0])+conf_matrix_LGB_eval[1, 0]+conf_matrix_LGB_eval[0, 1])\n",
    "LGB_eval_perf=[np.round(LGB_eval_final_accuracy,2),np.round(LGB_eval_final_precision,2),np.round(LGB_eval_final_sensitivity,2),np.round(LGB_eval_final_recall,2),np.round(LGB_eval_final_f1,2)]\n",
    "print(conf_matrix_LGB_eval)\n",
    "\n",
    "# print('--------------------------train performance--------------------------------------------')\n",
    "print(conf_matrix_LGB_train)\n",
    "print('Accuracy, precision, sensitivity,recall, F1_score for hexa-distributed train_test data by same LGB models are the following:',np.round(LGB_train_test_perf,2))\n",
    "# print('--------------------------test performance--------------------------------------------')\n",
    "print(conf_matrix_LGB_eval)\n",
    "print('Accuracy, precision, sensitivity,recall, F1_score, for hexa-distributed eval data by same LGB models are the following:',np.round(LGB_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the hexa-distributed system using LGB model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cf8d2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67748/67748 [==============================] - 160s 2ms/step - loss: 0.6632 - accuracy: 0.6336 - val_loss: 0.6568 - val_accuracy: 0.6341\n",
      "67748/67748 [==============================] - 63s 936us/step\n",
      "16937/16937 [==============================] - 16s 951us/step\n",
      "21172/21172 [==============================] - 19s 912us/step\n",
      "84685/84685 [==============================] - 78s 923us/step\n",
      "21172/21172 [==============================] - 20s 956us/step\n",
      "-------------------------single NN model train dataset performance--------------------------\n",
      "[[1717380  992523]\n",
      " [      0       0]]\n",
      "Accuracy, precision, sensitivity,recall, F1_score for train data by NN model are the following: [0.63 0.63 1.   0.   0.78]\n",
      "-------------------------single NN model evaluation dataset performance--------------------------\n",
      "[[429345 248131]\n",
      " [     0      0]]\n",
      "Accuracy, precision, sensitivity,recall, F1_score for eval data by NN model are the following: [0.63 0.63 1.   0.   0.78]\n",
      "time taken for the Single NN model to run and produce outcomes: 0:15:22.161940\n"
     ]
    }
   ],
   "source": [
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# import neural network libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "#Create a neural network model\n",
    "NN_model= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(24,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "NN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN_model.fit(X_raw_train,y_raw_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#store actual and predicted labels\n",
    "all_single_model_raw_train_actual_pred['NN_model_pred']= np.round(NN_model.predict(X_train))\n",
    "all_single_model_raw_test_actual_pred['NN_model_pred']= np.round(NN_model.predict(X_test))\n",
    "all_single_model_raw_eval_actual_pred['NN_model_pred']= np.round(NN_model.predict(X_raw_eval))\n",
    "\n",
    "# Evaluate the train dataset \n",
    "conf_matrix_NN_train=confusion_matrix(np.round(NN_model.predict(X_raw_train)),y_raw_train)\n",
    "NN_train_final_accuracy = (conf_matrix_NN_train[0, 0] + conf_matrix_NN_train[1, 1]) / np.sum(conf_matrix_NN_train)\n",
    "NN_train_final_precision = conf_matrix_NN_train[0, 0] / (conf_matrix_NN_train[0, 0] + conf_matrix_NN_train[0, 1])\n",
    "NN_train_final_sensitivity = conf_matrix_NN_train[0, 0] / (conf_matrix_NN_train[0, 0] + conf_matrix_NN_train[1, 0])\n",
    "NN_train_final_recall = conf_matrix_NN_train[1, 1] / (conf_matrix_NN_train[1, 1] + conf_matrix_NN_train[0, 1])\n",
    "NN_train_final_f1 = (2*conf_matrix_NN_train[0, 0])/ ((2*conf_matrix_NN_train[0, 0])+conf_matrix_NN_train[1, 0]+conf_matrix_NN_train[0, 1])\n",
    "NN_train_perf=[np.round(NN_train_final_accuracy,2),np.round(NN_train_final_precision,2),np.round(NN_train_final_sensitivity,2), np.round(NN_train_final_recall,2),np.round(NN_train_final_f1,2)]\n",
    "\n",
    "# Evaluate the test dataset \n",
    "conf_matrix_NN_eval=confusion_matrix(np.round(NN_model.predict(X_raw_eval)),y_raw_eval)\n",
    "NN_eval_final_accuracy = (conf_matrix_NN_eval[0, 0] + conf_matrix_NN_eval[1, 1]) / np.sum(conf_matrix_NN_eval)\n",
    "NN_eval_final_precision = conf_matrix_NN_eval[0, 0] / (conf_matrix_NN_eval[0, 0] + conf_matrix_NN_eval[0, 1])\n",
    "NN_eval_final_sensitivity = conf_matrix_NN_eval[0, 0] / (conf_matrix_NN_eval[0, 0] + conf_matrix_NN_eval[1, 0])\n",
    "NN_eval_final_recall = conf_matrix_NN_eval[1, 1] / (conf_matrix_NN_eval[1, 1] + conf_matrix_NN_eval[0, 1])\n",
    "NN_eval_final_f1 = (2*conf_matrix_NN_eval[0, 0])/ ((2*conf_matrix_NN_eval[0, 0])+conf_matrix_NN_eval[1, 0]+conf_matrix_NN_eval[0, 1])\n",
    "NN_eval_perf=[np.round(NN_eval_final_accuracy,2),np.round(NN_eval_final_precision,2),np.round(NN_eval_final_sensitivity,2),np.round(NN_eval_final_recall,2),np.round(NN_eval_final_f1,2)]\n",
    "\n",
    "print('-------------------------single NN model train dataset performance--------------------------')\n",
    "print(conf_matrix_NN_train)\n",
    "print('Accuracy, precision, sensitivity,recall, F1_score for train data by NN model are the following:',np.round(NN_train_perf,2))\n",
    "\n",
    "print('-------------------------single NN model evaluation dataset performance--------------------------')\n",
    "print(conf_matrix_NN_eval)\n",
    "print('Accuracy, precision, sensitivity,recall, F1_score for eval data by NN model are the following:',np.round(NN_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the Single NN model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "444d6c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12412/12412 [==============================] - 20s 2ms/step - loss: 29.4720 - accuracy: 0.7131 - val_loss: 0.4014 - val_accuracy: 0.9251\n",
      "Epoch 1/2\n",
      "7038/7038 [==============================] - 12s 2ms/step - loss: 50.5372 - accuracy: 0.6778 - val_loss: 0.7305 - val_accuracy: 0.5402\n",
      "Epoch 2/2\n",
      "7038/7038 [==============================] - 11s 2ms/step - loss: 0.6292 - accuracy: 0.6807 - val_loss: 0.7351 - val_accuracy: 0.5402\n",
      "Epoch 1/3\n",
      "7611/7611 [==============================] - 12s 2ms/step - loss: 12.5630 - accuracy: 0.6754 - val_loss: 0.7439 - val_accuracy: 0.5261\n",
      "Epoch 2/3\n",
      "7611/7611 [==============================] - 12s 2ms/step - loss: 0.6279 - accuracy: 0.6787 - val_loss: 0.7405 - val_accuracy: 0.5261\n",
      "Epoch 3/3\n",
      "7611/7611 [==============================] - 11s 2ms/step - loss: 0.6279 - accuracy: 0.6787 - val_loss: 0.7413 - val_accuracy: 0.5261\n",
      "6780/6780 [==============================] - 11s 2ms/step - loss: 0.8308 - accuracy: 0.6794 - val_loss: 0.7350 - val_accuracy: 0.5348\n",
      "Epoch 1/2\n",
      "6938/6938 [==============================] - 12s 2ms/step - loss: 15.4530 - accuracy: 0.6780 - val_loss: 0.7338 - val_accuracy: 0.5344\n",
      "Epoch 2/2\n",
      "6938/6938 [==============================] - 11s 2ms/step - loss: 0.6269 - accuracy: 0.6799 - val_loss: 0.7355 - val_accuracy: 0.5344\n",
      "Epoch 1/2\n",
      "7464/7464 [==============================] - 12s 2ms/step - loss: 10.2260 - accuracy: 0.6785 - val_loss: 0.7387 - val_accuracy: 0.5279\n",
      "Epoch 2/2\n",
      "7464/7464 [==============================] - 12s 2ms/step - loss: 0.6278 - accuracy: 0.6788 - val_loss: 0.7411 - val_accuracy: 0.5279\n",
      "11164/11164 [==============================] - 10s 930us/step\n",
      "6304/6304 [==============================] - 6s 893us/step\n",
      "6843/6843 [==============================] - 6s 923us/step\n",
      "6110/6110 [==============================] - 6s 899us/step\n",
      "6250/6250 [==============================] - 6s 898us/step\n",
      "6694/6694 [==============================] - 6s 886us/step\n",
      "4352/4352 [==============================] - 4s 903us/step\n",
      "2493/2493 [==============================] - 2s 882us/step\n",
      "2671/2671 [==============================] - 2s 897us/step\n",
      "2365/2365 [==============================] - 2s 865us/step\n",
      "2422/2422 [==============================] - 2s 897us/step\n",
      "2636/2636 [==============================] - 2s 894us/step\n",
      "5437/5437 [==============================] - 5s 896us/step\n",
      "3133/3133 [==============================] - 3s 892us/step\n",
      "3352/3352 [==============================] - 3s 887us/step\n",
      "3003/3003 [==============================] - 3s 897us/step\n",
      "3032/3032 [==============================] - 3s 881us/step\n",
      "3216/3216 [==============================] - 3s 931us/step\n",
      "15515/15515 [==============================] - 13s 845us/step\n",
      "8797/8797 [==============================] - 8s 902us/step\n",
      "9513/9513 [==============================] - 8s 876us/step\n",
      "8475/8475 [==============================] - 7s 877us/step\n",
      "8672/8672 [==============================] - 8s 923us/step\n",
      "9330/9330 [==============================] - 8s 863us/step\n",
      "5437/5437 [==============================] - 5s 896us/step\n",
      "3133/3133 [==============================] - 3s 874us/step\n",
      "3352/3352 [==============================] - 3s 903us/step\n",
      "3003/3003 [==============================] - 3s 945us/step\n",
      "3032/3032 [==============================] - 3s 903us/step\n",
      "3216/3216 [==============================] - 3s 903us/step\n",
      "[[1309620       0]\n",
      " [ 619960       0]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for distributed train_test data by same NN models are the following: [0.68  nan 0.    nan]\n",
      "[[349049  80296]\n",
      " [179562  68569]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for distributed eval data by same NN models are the following: [0.62 0.46 0.28 0.35]\n",
      "time taken for the hexa-distributed system using NN model to run and produce outcomes: 0:05:46.001270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25273141\\AppData\\Local\\Temp\\ipykernel_8868\\2508807441.py:135: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  NN_train_final_precision = (conf_matrix_NN_train[1, 1] / (conf_matrix_NN_train[1, 1] + conf_matrix_NN_train[0, 1]))\n"
     ]
    }
   ],
   "source": [
    "# remove neural network model confusion matrix variables\n",
    "del conf_matrix_NN_train,conf_matrix_NN_eval\n",
    "\n",
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# create neural network model datasets\n",
    "train_test_df1_NN = X_train_test_df1\n",
    "eval_df1_NN = X_eval_df1\n",
    "train_test_df2_NN = X_train_test_df2\n",
    "eval_df2_NN = X_eval_df2\n",
    "train_test_df3_NN = X_train_test_df3\n",
    "eval_df3_NN = X_eval_df3\n",
    "train_test_df4_NN = X_train_test_df4\n",
    "eval_df4_NN = X_eval_df4\n",
    "train_test_df5_NN = X_train_test_df5\n",
    "eval_df5_NN = X_eval_df5\n",
    "train_test_df6_NN = X_train_test_df6\n",
    "eval_df6_NN = X_eval_df6\n",
    "\n",
    "#Create 1st neural network model\n",
    "NN_df1= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(24,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "NN_df1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN_df1.fit(train_test_df1_NN,y_train_test_df1, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#Create 2nd neural network model\n",
    "NN_df2= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(24,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "NN_df2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN_df2.fit(train_test_df2_NN,y_train_test_df2, epochs=2, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#Create 3rd neural network model\n",
    "NN_df3= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(24,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "NN_df3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN_df3.fit(train_test_df3_NN,y_train_test_df3, epochs=3, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#Create 4th neural network model\n",
    "NN_df4= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(24,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "NN_df4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN_df4.fit(train_test_df4_NN,y_train_test_df4, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#Create 5th neural network model\n",
    "NN_df5= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(24,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "NN_df5.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN_df5.fit(train_test_df5_NN,y_train_test_df5, epochs=2, batch_size=32, validation_split=0.2)\n",
    "\n",
    "#Create 6th neural network model\n",
    "NN_df6= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(24,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "NN_df6.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN_df6.fit(train_test_df6_NN,y_train_test_df6, epochs=2, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# store actual and predicted labels\n",
    "all_distributed_model_train_df1_actual_pred['NN_model_pred']=np.round(NN_df1.predict(X_train_df1))\n",
    "all_distributed_model_train_df2_actual_pred['NN_model_pred']=np.round(NN_df2.predict(X_train_df2))\n",
    "all_distributed_model_train_df3_actual_pred['NN_model_pred']=np.round(NN_df3.predict(X_train_df3))\n",
    "all_distributed_model_train_df4_actual_pred['NN_model_pred']=np.round(NN_df4.predict(X_train_df4))\n",
    "all_distributed_model_train_df5_actual_pred['NN_model_pred']=np.round(NN_df5.predict(X_train_df5))\n",
    "all_distributed_model_train_df6_actual_pred['NN_model_pred']=np.round(NN_df6.predict(X_train_df6))\n",
    "\n",
    "all_distributed_model_test_df1_actual_pred['NN_model_pred']=np.round(NN_df1.predict(X_test_df1))\n",
    "all_distributed_model_test_df2_actual_pred['NN_model_pred']=np.round(NN_df2.predict(X_test_df2))\n",
    "all_distributed_model_test_df3_actual_pred['NN_model_pred']=np.round(NN_df3.predict(X_test_df3))\n",
    "all_distributed_model_test_df4_actual_pred['NN_model_pred']=np.round(NN_df4.predict(X_test_df4))\n",
    "all_distributed_model_test_df5_actual_pred['NN_model_pred']=np.round(NN_df5.predict(X_test_df5))\n",
    "all_distributed_model_test_df6_actual_pred['NN_model_pred']=np.round(NN_df6.predict(X_test_df6))\n",
    "\n",
    "all_distributed_model_eval_df1_actual_pred['NN_model_pred']=np.round(NN_df1.predict(X_eval_df1))\n",
    "all_distributed_model_eval_df2_actual_pred['NN_model_pred']=np.round(NN_df2.predict(X_eval_df2))\n",
    "all_distributed_model_eval_df3_actual_pred['NN_model_pred']=np.round(NN_df3.predict(X_eval_df3))\n",
    "all_distributed_model_eval_df4_actual_pred['NN_model_pred']=np.round(NN_df4.predict(X_eval_df4))\n",
    "all_distributed_model_eval_df5_actual_pred['NN_model_pred']=np.round(NN_df5.predict(X_eval_df5))\n",
    "all_distributed_model_eval_df6_actual_pred['NN_model_pred']=np.round(NN_df6.predict(X_eval_df6))\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 NN models for train_testing dataset\n",
    "NN_train_1 = confusion_matrix(y_train_test_df1,np.round(NN_df1.predict(train_test_df1_NN)))\n",
    "NN_train_2 = confusion_matrix(y_train_test_df2,np.round(NN_df2.predict(train_test_df2_NN)))\n",
    "NN_train_3 = confusion_matrix(y_train_test_df3,np.round(NN_df3.predict(train_test_df3_NN)))\n",
    "NN_train_4 = confusion_matrix(y_train_test_df4,np.round(NN_df4.predict(train_test_df4_NN)))\n",
    "NN_train_5 = confusion_matrix(y_train_test_df5,np.round(NN_df5.predict(train_test_df5_NN)))\n",
    "NN_train_6 = confusion_matrix(y_train_test_df6,np.round(NN_df6.predict(train_test_df6_NN)))\n",
    "conf_matrix_NN_train=NN_train_1 +NN_train_2 + NN_train_3 + NN_train_4 + NN_train_5 +NN_train_6\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 NN models for evaluation dataset\n",
    "NN_eval_1 = confusion_matrix(y_eval_df1,np.round(NN_df1.predict(eval_df1_NN)))\n",
    "NN_eval_2 = confusion_matrix(y_eval_df2,np.round(NN_df2.predict(eval_df2_NN)))\n",
    "NN_eval_3 = confusion_matrix(y_eval_df3,np.round(NN_df3.predict(eval_df3_NN)))\n",
    "NN_eval_4 = confusion_matrix(y_eval_df4,np.round(NN_df4.predict(eval_df4_NN)))\n",
    "NN_eval_5 = confusion_matrix(y_eval_df5,np.round(NN_df5.predict(eval_df5_NN)))\n",
    "NN_eval_6 = confusion_matrix(y_eval_df6,np.round(NN_df6.predict(eval_df6_NN)))\n",
    "conf_matrix_NN_eval=NN_eval_1 +NN_eval_2 + NN_eval_3 + NN_eval_4 + NN_eval_5 +NN_eval_6\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 NN models for train dataset\n",
    "NN_train_final_accuracy = (conf_matrix_NN_train[0, 0] + conf_matrix_NN_train[1, 1]) / np.sum(conf_matrix_NN_train)\n",
    "NN_train_final_precision = (conf_matrix_NN_train[1, 1] / (conf_matrix_NN_train[1, 1] + conf_matrix_NN_train[0, 1]))\n",
    "NN_train_final_recall = conf_matrix_NN_train[1, 1] / (conf_matrix_NN_train[1, 1] + conf_matrix_NN_train[1, 0])\n",
    "NN_train_final_f1 = 2 * (NN_train_final_precision * NN_train_final_recall) / (NN_train_final_precision + NN_train_final_recall)\n",
    "\n",
    "NN_train_test_perf=[np.round(NN_train_final_accuracy,2),np.round(NN_train_final_precision,2),np.round(NN_train_final_recall,2),np.round(NN_train_final_f1,2)]\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 NN models for evaluate dataset\n",
    "NN_eval_final_accuracy = (conf_matrix_NN_eval[0, 0] + conf_matrix_NN_eval[1, 1]) / np.sum(conf_matrix_NN_eval)\n",
    "NN_eval_final_precision = conf_matrix_NN_eval[1, 1] / (conf_matrix_NN_eval[1, 1] + conf_matrix_NN_eval[0, 1])\n",
    "NN_eval_final_recall = conf_matrix_NN_eval[1, 1] / (conf_matrix_NN_eval[1, 1] + conf_matrix_NN_eval[1, 0])\n",
    "NN_eval_final_f1 = 2 * (NN_eval_final_precision * NN_eval_final_recall) / (NN_eval_final_precision + NN_eval_final_recall)\n",
    "\n",
    "NN_eval_perf=[np.round(NN_eval_final_accuracy,2),np.round(NN_eval_final_precision,2),np.round(NN_eval_final_recall,2),np.round(NN_eval_final_f1,2)]\n",
    "\n",
    "# print('--------------------------train_test performance--------------------------------------------')\n",
    "print(conf_matrix_NN_train)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for distributed train_test data by same NN models are the following:',np.round(NN_train_test_perf,2))\n",
    "# print('--------------------------test performance--------------------------------------------')\n",
    "print(conf_matrix_NN_eval)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for distributed eval data by same NN models are the following:',np.round(NN_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the hexa-distributed system using NN model to run and produce outcomes:', finish_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8b0335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------single RF model evaluation dataset performance--------------------------\n",
      "-------------------------single RF model train dataset performance--------------------------\n",
      "[[1684908  347444]\n",
      " [  32472  645079]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for  train data by RF model are the following: [0.86 0.83 0.98 0.65 0.9 ]\n",
      "[[369187 191057]\n",
      " [ 60158  57074]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for  eval data by same RF model are the following: [0.63 0.66 0.86 0.23 0.75]\n",
      "time taken for the Single RF model to run and produce outcomes: 0:00:56.546062\n"
     ]
    }
   ],
   "source": [
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# import Random Forest library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "RF_model = RandomForestClassifier(n_estimators=2)\n",
    "\n",
    "# Train the Random Forest model\n",
    "RF_model.fit(X_raw_train, y_raw_train)\n",
    "\n",
    "#store actual and predicted labels\n",
    "all_single_model_raw_train_actual_pred['RF_model_pred']= np.round(RF_model.predict(X_train))\n",
    "all_single_model_raw_test_actual_pred['RF_model_pred']= np.round(RF_model.predict(X_test))\n",
    "all_single_model_raw_eval_actual_pred['RF_model_pred']= np.round(RF_model.predict(X_raw_eval))\n",
    "\n",
    "# Evaluate the train dataset \n",
    "\n",
    "conf_matrix_RF_train=confusion_matrix(np.round(RF_model.predict(X_raw_train)),y_raw_train)\n",
    "RF_train_final_accuracy = (conf_matrix_RF_train[0, 0] + conf_matrix_RF_train[1, 1]) / np.sum(conf_matrix_RF_train)\n",
    "RF_train_final_precision = conf_matrix_RF_train[0, 0] / (conf_matrix_RF_train[0, 0] + conf_matrix_RF_train[0, 1])\n",
    "RF_train_final_sensitivity = conf_matrix_RF_train[0, 0] / (conf_matrix_RF_train[0, 0] + conf_matrix_RF_train[1, 0])\n",
    "RF_train_final_recall = conf_matrix_RF_train[1, 1] / (conf_matrix_RF_train[1, 1] + conf_matrix_RF_train[0, 1])\n",
    "RF_train_final_f1 = (2*conf_matrix_RF_train[0, 0])/ ((2*conf_matrix_RF_train[0, 0])+conf_matrix_RF_train[1, 0]+conf_matrix_RF_train[0, 1])\n",
    "RF_train_test_perf=[np.round(RF_train_final_accuracy,2),np.round(RF_train_final_precision,2),np.round(RF_train_final_sensitivity,2), np.round(RF_train_final_recall,2),np.round(RF_train_final_f1,2)]\n",
    "\n",
    "# Evaluate the test dataset \n",
    "print('-------------------------single RF model evaluation dataset performance--------------------------')\n",
    "conf_matrix_RF_eval=confusion_matrix(np.round(RF_model.predict(X_raw_eval)),y_raw_eval)\n",
    "RF_eval_final_accuracy = (conf_matrix_RF_eval[0, 0] + conf_matrix_RF_eval[1, 1]) / np.sum(conf_matrix_RF_eval)\n",
    "RF_eval_final_precision = conf_matrix_RF_eval[0, 0] / (conf_matrix_RF_eval[0, 0] + conf_matrix_RF_eval[0, 1])\n",
    "RF_eval_final_sensitivity = conf_matrix_RF_eval[0, 0] / (conf_matrix_RF_eval[0, 0] + conf_matrix_RF_eval[1, 0])\n",
    "RF_eval_final_recall = conf_matrix_RF_eval[1, 1] / (conf_matrix_RF_eval[1, 1] + conf_matrix_RF_eval[0, 1])\n",
    "RF_eval_final_f1 = (2*conf_matrix_RF_eval[0, 0])/ ((2*conf_matrix_RF_eval[0, 0])+conf_matrix_RF_eval[1, 0]+conf_matrix_RF_eval[0, 1])\n",
    "RF_eval_perf=[np.round(RF_eval_final_accuracy,2),np.round(RF_eval_final_precision,2),np.round(RF_eval_final_sensitivity,2),np.round(RF_eval_final_recall,2),np.round(RF_eval_final_f1,2)]\n",
    "print('-------------------------single RF model train dataset performance--------------------------')\n",
    "print(conf_matrix_RF_train)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for  train data by RF model are the following:',np.round(RF_train_test_perf,2))\n",
    "print(conf_matrix_RF_eval)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for  eval data by same RF model are the following:',np.round(RF_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the Single RF model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e126e7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1275979  188255]\n",
      " [  33641  431705]]\n",
      "Accuracy, precision,sensitivity, recall, F1_score for hexa-distributed train_test data by same RF models are the following: [0.86 0.83 0.98 0.65 0.9 ]\n",
      "[[329796 162586]\n",
      " [ 99549  85545]]\n",
      "Accuracy, precision,sensitivity, recall, F1_score for hexa-distributed eval data by same RF models are the following: [0.61 0.67 0.77 0.34 0.72]\n",
      "time taken for the hexa-distributed system using RF model to run and produce outcomes: 0:00:16.110942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# remove random forest model confusion matrix variables\n",
    "del conf_matrix_RF_train,conf_matrix_RF_eval\n",
    "\n",
    "# import random forest library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Create 6 Random forest datasets\n",
    "train_test_df1_RF = X_train_test_df1\n",
    "eval_df1_RF = X_eval_df1\n",
    "train_test_df2_RF = X_train_test_df2\n",
    "eval_df2_RF = X_eval_df2\n",
    "train_test_df3_RF = X_train_test_df3\n",
    "eval_df3_RF = X_eval_df3\n",
    "train_test_df4_RF = X_train_test_df4\n",
    "eval_df4_RF = X_eval_df4\n",
    "train_test_df5_RF = X_train_test_df5\n",
    "eval_df5_RF = X_eval_df5\n",
    "train_test_df6_RF = X_train_test_df6\n",
    "eval_df6_RF = X_eval_df6\n",
    "\n",
    "# train 6 Random forest models \n",
    "RF_df1 = RandomForestClassifier(n_estimators=2)\n",
    "RF_df1.fit(train_test_df1_RF, y_train_test_df1)\n",
    "RF_df2 = RandomForestClassifier(n_estimators=2)\n",
    "RF_df2.fit(train_test_df2_RF, y_train_test_df2)\n",
    "RF_df3 = RandomForestClassifier(n_estimators=2)\n",
    "RF_df3.fit(train_test_df3_RF, y_train_test_df3)\n",
    "RF_df4 = RandomForestClassifier(n_estimators=1)\n",
    "RF_df4.fit(train_test_df4_RF, y_train_test_df4)\n",
    "RF_df5 =RandomForestClassifier(n_estimators=2)\n",
    "RF_df5.fit(train_test_df5_RF, y_train_test_df5)\n",
    "RF_df6 = RandomForestClassifier(n_estimators=2)\n",
    "RF_df6.fit(train_test_df6_RF, y_train_test_df6)\n",
    "\n",
    "#store actual and predicted outcomes\n",
    "all_distributed_model_train_df1_actual_pred['RF_model_pred']=np.round(RF_df1.predict(X_train_df1))\n",
    "all_distributed_model_train_df2_actual_pred['RF_model_pred']=np.round(RF_df2.predict(X_train_df2))\n",
    "all_distributed_model_train_df3_actual_pred['RF_model_pred']=np.round(RF_df3.predict(X_train_df3))\n",
    "all_distributed_model_train_df4_actual_pred['RF_model_pred']=np.round(RF_df4.predict(X_train_df4))\n",
    "all_distributed_model_train_df5_actual_pred['RF_model_pred']=np.round(RF_df5.predict(X_train_df5))\n",
    "all_distributed_model_train_df6_actual_pred['RF_model_pred']=np.round(RF_df6.predict(X_train_df6))\n",
    "\n",
    "all_distributed_model_test_df1_actual_pred['RF_model_pred']=np.round(RF_df1.predict(X_test_df1))\n",
    "all_distributed_model_test_df2_actual_pred['RF_model_pred']=np.round(RF_df2.predict(X_test_df2))\n",
    "all_distributed_model_test_df3_actual_pred['RF_model_pred']=np.round(RF_df3.predict(X_test_df3))\n",
    "all_distributed_model_test_df4_actual_pred['RF_model_pred']=np.round(RF_df4.predict(X_test_df4))\n",
    "all_distributed_model_test_df5_actual_pred['RF_model_pred']=np.round(RF_df5.predict(X_test_df5))\n",
    "all_distributed_model_test_df6_actual_pred['RF_model_pred']=np.round(RF_df6.predict(X_test_df6))\n",
    "\n",
    "all_distributed_model_eval_df1_actual_pred['RF_model_pred']=np.round(RF_df1.predict(X_eval_df1))\n",
    "all_distributed_model_eval_df2_actual_pred['RF_model_pred']=np.round(RF_df2.predict(X_eval_df2))\n",
    "all_distributed_model_eval_df3_actual_pred['RF_model_pred']=np.round(RF_df3.predict(X_eval_df3))\n",
    "all_distributed_model_eval_df4_actual_pred['RF_model_pred']=np.round(RF_df4.predict(X_eval_df4))\n",
    "all_distributed_model_eval_df5_actual_pred['RF_model_pred']=np.round(RF_df5.predict(X_eval_df5))\n",
    "all_distributed_model_eval_df6_actual_pred['RF_model_pred']=np.round(RF_df6.predict(X_eval_df6))\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score 6 RF models  for train_testing dataset\n",
    "RF_train_1 = confusion_matrix(np.round(RF_df1.predict(train_test_df1_RF)),y_train_test_df1)\n",
    "RF_train_2 = confusion_matrix(np.round(RF_df2.predict(train_test_df2_RF)),y_train_test_df2)\n",
    "RF_train_3 = confusion_matrix(np.round(RF_df3.predict(train_test_df3_RF)),y_train_test_df3)\n",
    "RF_train_4 = confusion_matrix(np.round(RF_df4.predict(train_test_df4_RF)),y_train_test_df4)\n",
    "RF_train_5 = confusion_matrix(np.round(RF_df5.predict(train_test_df5_RF)),y_train_test_df5)\n",
    "RF_train_6 = confusion_matrix(np.round(RF_df6.predict(train_test_df6_RF)),y_train_test_df6)\n",
    "conf_matrix_RF_train=RF_train_1 +RF_train_2 + RF_train_3 + RF_train_4 + RF_train_5 +RF_train_6\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 RF models for evaluation dataset\n",
    "RF_eval_1 = confusion_matrix(np.round(RF_df1.predict(eval_df1_RF)),y_eval_df1)\n",
    "RF_eval_2 = confusion_matrix(np.round(RF_df2.predict(eval_df2_RF)),y_eval_df2)\n",
    "RF_eval_3 = confusion_matrix(np.round(RF_df3.predict(eval_df3_RF)),y_eval_df3)\n",
    "RF_eval_4 = confusion_matrix(np.round(RF_df4.predict(eval_df4_RF)),y_eval_df4)\n",
    "RF_eval_5 = confusion_matrix(np.round(RF_df5.predict(eval_df5_RF)),y_eval_df5)\n",
    "RF_eval_6 = confusion_matrix(np.round(RF_df6.predict(eval_df6_RF)),y_eval_df6)\n",
    "conf_matrix_RF_eval=RF_eval_1 +RF_eval_2 + RF_eval_3 + RF_eval_4 + RF_eval_5 +RF_eval_6\n",
    "\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 NN modelsfor train dataset\n",
    "RF_train_final_accuracy = (conf_matrix_RF_train[0, 0] + conf_matrix_RF_train[1, 1]) / np.sum(conf_matrix_RF_train)\n",
    "RF_train_final_precision = conf_matrix_RF_train[0, 0] / (conf_matrix_RF_train[0, 0] + conf_matrix_RF_train[0, 1])\n",
    "RF_train_final_sensitivity = conf_matrix_RF_train[0, 0] / (conf_matrix_RF_train[0, 0] + conf_matrix_RF_train[1, 0])\n",
    "RF_train_final_recall = conf_matrix_RF_train[1, 1] / (conf_matrix_RF_train[1, 1] + conf_matrix_RF_train[0, 1])\n",
    "RF_train_final_f1 = (2*conf_matrix_RF_train[0, 0])/ ((2*conf_matrix_RF_train[0, 0])+conf_matrix_RF_train[1, 0]+conf_matrix_RF_train[0, 1])\n",
    "RF_train_perf=[np.round(RF_train_final_accuracy,2),np.round(RF_train_final_precision,2),np.round(RF_train_final_sensitivity,2), np.round(RF_train_final_recall,2),np.round(RF_train_final_f1,2)]\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 NN modelsfor evaluate dataset\n",
    "RF_eval_final_accuracy = (conf_matrix_RF_eval[0, 0] + conf_matrix_RF_eval[1, 1]) / np.sum(conf_matrix_RF_eval)\n",
    "RF_eval_final_precision = conf_matrix_RF_eval[0, 0] / (conf_matrix_RF_eval[0, 0] + conf_matrix_RF_eval[0, 1])\n",
    "RF_eval_final_sensitivity = conf_matrix_RF_eval[0, 0] / (conf_matrix_RF_eval[0, 0] + conf_matrix_RF_eval[1, 0])\n",
    "RF_eval_final_recall = conf_matrix_RF_eval[1, 1] / (conf_matrix_RF_eval[1, 1] + conf_matrix_RF_eval[0, 1])\n",
    "RF_eval_final_f1 = (2*conf_matrix_RF_eval[0, 0])/ ((2*conf_matrix_RF_eval[0, 0])+conf_matrix_RF_eval[1, 0]+conf_matrix_RF_eval[0, 1])\n",
    "RF_eval_perf=[np.round(RF_eval_final_accuracy,2),np.round(RF_eval_final_precision,2),np.round(RF_eval_final_sensitivity,2),np.round(RF_eval_final_recall,2),np.round(RF_eval_final_f1,2)]\n",
    "\n",
    "# print('--------------------------train_test performance--------------------------------------------')\n",
    "print(conf_matrix_RF_train)\n",
    "print('Accuracy, precision,sensitivity, recall, F1_score for hexa-distributed train_test data by same RF models are the following:',np.round(RF_train_test_perf,2))\n",
    "# print('--------------------------test performance--------------------------------------------')\n",
    "print(conf_matrix_RF_eval)\n",
    "print('Accuracy, precision,sensitivity, recall, F1_score for hexa-distributed eval data by same RF models are the following:',np.round(RF_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the hexa-distributed system using RF model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77d4c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.64252\n",
      "[1]\ttest-logloss:0.63048\n",
      "[2]\ttest-logloss:0.62036\n",
      "[3]\ttest-logloss:0.61181\n",
      "[4]\ttest-logloss:0.60453\n",
      "[5]\ttest-logloss:0.59835\n",
      "[6]\ttest-logloss:0.59302\n",
      "[7]\ttest-logloss:0.58847\n",
      "[8]\ttest-logloss:0.58454\n",
      "[9]\ttest-logloss:0.58118\n",
      "[10]\ttest-logloss:0.57828\n",
      "[11]\ttest-logloss:0.57577\n",
      "[12]\ttest-logloss:0.57361\n",
      "[13]\ttest-logloss:0.57173\n",
      "[14]\ttest-logloss:0.57011\n",
      "[15]\ttest-logloss:0.56871\n",
      "[16]\ttest-logloss:0.56748\n",
      "[17]\ttest-logloss:0.56643\n",
      "[18]\ttest-logloss:0.56552\n",
      "[19]\ttest-logloss:0.56473\n",
      "[20]\ttest-logloss:0.56406\n",
      "[21]\ttest-logloss:0.56346\n",
      "[22]\ttest-logloss:0.56294\n",
      "[23]\ttest-logloss:0.56246\n",
      "[24]\ttest-logloss:0.56206\n",
      "[25]\ttest-logloss:0.56172\n",
      "[26]\ttest-logloss:0.56142\n",
      "[27]\ttest-logloss:0.56116\n",
      "[28]\ttest-logloss:0.56092\n",
      "[29]\ttest-logloss:0.56072\n",
      "[30]\ttest-logloss:0.56057\n",
      "[31]\ttest-logloss:0.56039\n",
      "[32]\ttest-logloss:0.56027\n",
      "[33]\ttest-logloss:0.56015\n",
      "[34]\ttest-logloss:0.56002\n",
      "[35]\ttest-logloss:0.55993\n",
      "[36]\ttest-logloss:0.55981\n",
      "[37]\ttest-logloss:0.55975\n",
      "[38]\ttest-logloss:0.55967\n",
      "[39]\ttest-logloss:0.55963\n",
      "[40]\ttest-logloss:0.55958\n",
      "[41]\ttest-logloss:0.55940\n",
      "[42]\ttest-logloss:0.55936\n",
      "[43]\ttest-logloss:0.55934\n",
      "[44]\ttest-logloss:0.55930\n",
      "[45]\ttest-logloss:0.55927\n",
      "[46]\ttest-logloss:0.55924\n",
      "[47]\ttest-logloss:0.55922\n",
      "[48]\ttest-logloss:0.55918\n",
      "[49]\ttest-logloss:0.55917\n",
      "[50]\ttest-logloss:0.55913\n",
      "[51]\ttest-logloss:0.55906\n",
      "[52]\ttest-logloss:0.55901\n",
      "[53]\ttest-logloss:0.55897\n",
      "[54]\ttest-logloss:0.55893\n",
      "[55]\ttest-logloss:0.55893\n",
      "[56]\ttest-logloss:0.55885\n",
      "[57]\ttest-logloss:0.55884\n",
      "[58]\ttest-logloss:0.55882\n",
      "[59]\ttest-logloss:0.55880\n",
      "[60]\ttest-logloss:0.55878\n",
      "[61]\ttest-logloss:0.55873\n",
      "[62]\ttest-logloss:0.55871\n",
      "[63]\ttest-logloss:0.55868\n",
      "[64]\ttest-logloss:0.55867\n",
      "[65]\ttest-logloss:0.55862\n",
      "[66]\ttest-logloss:0.55861\n",
      "[67]\ttest-logloss:0.55860\n",
      "[68]\ttest-logloss:0.55858\n",
      "[69]\ttest-logloss:0.55855\n",
      "[70]\ttest-logloss:0.55850\n",
      "-------------------------single XGB model train dataset peXGBormance--------------------------\n",
      "-------------------------single XGB model evaluation dataset peXGBormance--------------------------\n",
      "[[1691040  949026]\n",
      " [  26340   43497]]\n",
      "Accuracy, precision,sensitivity, recall, F1_score for train data by single XGB model are the following: [0.64 0.64 0.98 0.04 0.78]\n",
      "[[422639 237350]\n",
      " [  6706  10781]]\n",
      "Accuracy, precision, sensitivity, recall, F1_score for eval data by single XGB model are the following: [0.64 0.64 0.98 0.04 0.78]\n",
      "time taken for the Single XGB model to run and produce outcomes: 0:00:17.074182\n"
     ]
    }
   ],
   "source": [
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# import xgboost library\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "drawtrain = xgb.DMatrix(X_raw_train.values, label=y_raw_train.values)\n",
    "dtrain = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "dtest = xgb.DMatrix(X_test.values, label=y_test.values)\n",
    "draweval = xgb.DMatrix(X_raw_eval.values)\n",
    "\n",
    "# Set parameters for the XGBoost model\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",  # for binary classification\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.1\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 71\n",
    "XGB_model = xgb.train(params, dtrain, num_round, evals=[(dtest, \"test\")])\n",
    "\n",
    "# store actual and predicted outcomes\n",
    "all_single_model_raw_train_actual_pred['XGB_model_pred']= np.round(XGB_model.predict(dtrain))\n",
    "all_single_model_raw_test_actual_pred['XGB_model_pred']= np.round(XGB_model.predict(dtest))\n",
    "all_single_model_raw_eval_actual_pred['XGB_model_pred']= np.round(XGB_model.predict(draweval))\n",
    "\n",
    "# Evaluate the train dataset \n",
    "print('-------------------------single XGB model train dataset peXGBormance--------------------------')\n",
    "conf_matrix_XGB_train=confusion_matrix(np.round(XGB_model.predict(drawtrain)),y_raw_train)\n",
    "XGB_train_final_accuracy = (conf_matrix_XGB_train[0, 0] + conf_matrix_XGB_train[1, 1]) / np.sum(conf_matrix_XGB_train)\n",
    "XGB_train_final_precision = conf_matrix_XGB_train[0, 0] / (conf_matrix_XGB_train[0, 0] + conf_matrix_XGB_train[0, 1])\n",
    "XGB_train_final_sensitivity = conf_matrix_XGB_train[0, 0] / (conf_matrix_XGB_train[0, 0] + conf_matrix_XGB_train[1, 0])\n",
    "XGB_train_final_recall = conf_matrix_XGB_train[1, 1] / (conf_matrix_XGB_train[1, 1] + conf_matrix_XGB_train[0, 1])\n",
    "XGB_train_final_f1 = (2*conf_matrix_XGB_train[0, 0])/ ((2*conf_matrix_XGB_train[0, 0])+conf_matrix_XGB_train[1, 0]+conf_matrix_XGB_train[0, 1])\n",
    "XGB_train_perf=[np.round(XGB_train_final_accuracy,2),np.round(XGB_train_final_precision,2),np.round(XGB_train_final_sensitivity,2), np.round(XGB_train_final_recall,2),np.round(XGB_train_final_f1,2)]\n",
    "\n",
    "# Evaluate the test dataset \n",
    "print('-------------------------single XGB model evaluation dataset peXGBormance--------------------------')\n",
    "conf_matrix_XGB_eval=confusion_matrix( np.round(XGB_model.predict(draweval)),y_raw_eval)\n",
    "XGB_eval_final_accuracy = (conf_matrix_XGB_eval[0, 0] + conf_matrix_XGB_eval[1, 1]) / np.sum(conf_matrix_XGB_eval)\n",
    "XGB_eval_final_precision = conf_matrix_XGB_eval[0, 0] / (conf_matrix_XGB_eval[0, 0] + conf_matrix_XGB_eval[0, 1])\n",
    "XGB_eval_final_sensitivity = conf_matrix_XGB_eval[0, 0] / (conf_matrix_XGB_eval[0, 0] + conf_matrix_XGB_eval[1, 0])\n",
    "XGB_eval_final_recall = conf_matrix_XGB_eval[1, 1] / (conf_matrix_XGB_eval[1, 1] + conf_matrix_XGB_eval[0, 1])\n",
    "XGB_eval_final_f1 = (2*conf_matrix_XGB_eval[0, 0])/ ((2*conf_matrix_XGB_eval[0, 0])+conf_matrix_XGB_eval[1, 0]+conf_matrix_XGB_eval[0, 1])\n",
    "XGB_eval_perf=[np.round(XGB_eval_final_accuracy,2),np.round(XGB_eval_final_precision,2),np.round(XGB_eval_final_sensitivity,2),np.round(XGB_eval_final_recall,2),np.round(XGB_eval_final_f1,2)]\n",
    "\n",
    "print(conf_matrix_XGB_train)\n",
    "print('Accuracy, precision,sensitivity, recall, F1_score for train data by single XGB model are the following:',np.round(XGB_train_perf,2))\n",
    "\n",
    "print(conf_matrix_XGB_eval)\n",
    "print('Accuracy, precision, sensitivity, recall, F1_score for eval data by single XGB model are the following:',np.round(XGB_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the Single XGB model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1d98811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest_df1-logloss:0.40056\n",
      "[1]\ttest_df1-logloss:0.37193\n",
      "[2]\ttest_df1-logloss:0.34747\n",
      "[3]\ttest_df1-logloss:0.32632\n",
      "[4]\ttest_df1-logloss:0.30811\n",
      "[5]\ttest_df1-logloss:0.29235\n",
      "[6]\ttest_df1-logloss:0.27866\n",
      "[7]\ttest_df1-logloss:0.26673\n",
      "[8]\ttest_df1-logloss:0.25631\n",
      "[9]\ttest_df1-logloss:0.24728\n",
      "[10]\ttest_df1-logloss:0.23941\n",
      "[11]\ttest_df1-logloss:0.23254\n",
      "[12]\ttest_df1-logloss:0.22659\n",
      "[13]\ttest_df1-logloss:0.22136\n",
      "[14]\ttest_df1-logloss:0.21681\n",
      "[15]\ttest_df1-logloss:0.21280\n",
      "[16]\ttest_df1-logloss:0.20930\n",
      "[17]\ttest_df1-logloss:0.20625\n",
      "[18]\ttest_df1-logloss:0.20358\n",
      "[19]\ttest_df1-logloss:0.20127\n",
      "[20]\ttest_df1-logloss:0.19915\n",
      "[21]\ttest_df1-logloss:0.19740\n",
      "[22]\ttest_df1-logloss:0.19580\n",
      "[23]\ttest_df1-logloss:0.19427\n",
      "[24]\ttest_df1-logloss:0.19307\n",
      "[25]\ttest_df1-logloss:0.19200\n",
      "[26]\ttest_df1-logloss:0.19107\n",
      "[27]\ttest_df1-logloss:0.19029\n",
      "[28]\ttest_df1-logloss:0.18935\n",
      "[29]\ttest_df1-logloss:0.18852\n",
      "[30]\ttest_df1-logloss:0.18790\n",
      "[31]\ttest_df1-logloss:0.18736\n",
      "[32]\ttest_df1-logloss:0.18689\n",
      "[33]\ttest_df1-logloss:0.18638\n",
      "[34]\ttest_df1-logloss:0.18602\n",
      "[35]\ttest_df1-logloss:0.18536\n",
      "[36]\ttest_df1-logloss:0.18504\n",
      "[37]\ttest_df1-logloss:0.18477\n",
      "[38]\ttest_df1-logloss:0.18443\n",
      "[39]\ttest_df1-logloss:0.18391\n",
      "[40]\ttest_df1-logloss:0.18372\n",
      "[41]\ttest_df1-logloss:0.18349\n",
      "[42]\ttest_df1-logloss:0.18330\n",
      "[43]\ttest_df1-logloss:0.18283\n",
      "[44]\ttest_df1-logloss:0.18265\n",
      "[45]\ttest_df1-logloss:0.18254\n",
      "[46]\ttest_df1-logloss:0.18230\n",
      "[47]\ttest_df1-logloss:0.18212\n",
      "[48]\ttest_df1-logloss:0.18200\n",
      "[49]\ttest_df1-logloss:0.18192\n",
      "[50]\ttest_df1-logloss:0.18186\n",
      "[51]\ttest_df1-logloss:0.18174\n",
      "[52]\ttest_df1-logloss:0.18165\n",
      "[53]\ttest_df1-logloss:0.18157\n",
      "[54]\ttest_df1-logloss:0.18148\n",
      "[0]\ttest_df2-logloss:0.72444\n",
      "[0]\ttest_df3-logloss:0.73532\n",
      "[0]\ttest_df4-logloss:0.73243\n",
      "[0]\ttest_df5-logloss:0.73219\n",
      "[0]\ttest_df6-logloss:0.73426\n",
      "[[935605 503740]\n",
      " [374015 116220]]\n",
      "Accuracy, precision,sensitivity, recall, F1_score for distributed train data by same XGB models are the following: [0.55 0.65 0.71 0.19 0.68]\n",
      "[[429343 244485]\n",
      " [     2   3646]]\n",
      "Accuracy, precision,sensitivity, recall, F1_score for distributed eval data by same XGB models are the following: [0.64 0.64 1.   0.01 0.78]\n",
      "time taken for the hexa-distributed system using XGB model to run and produce outcomes: 0:00:06.391512\n"
     ]
    }
   ],
   "source": [
    "# remove XG boost model confusion matrix variables\n",
    "del conf_matrix_XGB_train,conf_matrix_XGB_eval\n",
    "\n",
    "# import xgboost library\n",
    "import xgboost as XGB\n",
    "\n",
    "# store the start time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Create the LightGBM datasets\n",
    "d_train_test_df1=XGB.DMatrix(X_train_test_df1)\n",
    "d_train_test_df2=XGB.DMatrix(X_train_test_df2)\n",
    "d_train_test_df3=XGB.DMatrix(X_train_test_df3)\n",
    "d_train_test_df4=XGB.DMatrix(X_train_test_df4)\n",
    "d_train_test_df5=XGB.DMatrix(X_train_test_df5)\n",
    "d_train_test_df6=XGB.DMatrix(X_train_test_df6)\n",
    "\n",
    "d_eval_df1=XGB.DMatrix(X_eval_df1)\n",
    "d_eval_df2=XGB.DMatrix(X_eval_df2)\n",
    "d_eval_df3=XGB.DMatrix(X_eval_df3)\n",
    "d_eval_df4=XGB.DMatrix(X_eval_df4)\n",
    "d_eval_df5=XGB.DMatrix(X_eval_df5)\n",
    "d_eval_df6=XGB.DMatrix(X_eval_df6)\n",
    "\n",
    "train_df1_XGB = XGB.DMatrix(X_train_df1, label=y_train_df1)\n",
    "test_df1_XGB = XGB.DMatrix(X_test_df1, label=y_test_df1)\n",
    "train_df2_XGB = XGB.DMatrix(X_train_df2, label=y_train_df2)\n",
    "test_df2_XGB = XGB.DMatrix(X_test_df2, label=y_test_df2)\n",
    "train_df3_XGB = XGB.DMatrix(X_train_df3, label=y_train_df3)\n",
    "test_df3_XGB = XGB.DMatrix(X_test_df3, label=y_test_df3)\n",
    "train_df4_XGB = XGB.DMatrix(X_train_df4, label=y_train_df4)\n",
    "test_df4_XGB = XGB.DMatrix(X_test_df4, label=y_test_df4)\n",
    "train_df5_XGB = XGB.DMatrix(X_train_df5, label=y_train_df5)\n",
    "test_df5_XGB = XGB.DMatrix(X_test_df5, label=y_test_df5)\n",
    "train_df6_XGB = XGB.DMatrix(X_train_df6, label=y_train_df6)\n",
    "test_df6_XGB = XGB.DMatrix(X_test_df6, label=y_test_df6)\n",
    "\n",
    "# Set parameters for the XGBoost model\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",  # for binary classification\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.1\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "XGB_df1 = XGB.train(params, train_df1_XGB, 55, evals=[(test_df1_XGB, \"test_df1\")])\n",
    "XGB_df2 = XGB.train(params, train_df2_XGB, 1, evals=[(test_df2_XGB, \"test_df2\")])\n",
    "XGB_df3 = XGB.train(params, train_df3_XGB, 1, evals=[(test_df3_XGB, \"test_df3\")])\n",
    "XGB_df4 = XGB.train(params, train_df4_XGB, 1, evals=[(test_df4_XGB, \"test_df4\")])\n",
    "XGB_df5 = XGB.train(params, train_df5_XGB, 1, evals=[(test_df5_XGB, \"test_df5\")])\n",
    "XGB_df6 = XGB.train(params, train_df6_XGB, 1, evals=[(test_df6_XGB, \"test_df6\")])\n",
    "\n",
    "#store actual and predicted outcomes\n",
    "all_distributed_model_train_df1_actual_pred['XGB_model_pred']=np.round(XGB_df1.predict(train_df1_XGB))\n",
    "all_distributed_model_train_df2_actual_pred['XGB_model_pred']=np.round(XGB_df2.predict(train_df2_XGB))\n",
    "all_distributed_model_train_df3_actual_pred['XGB_model_pred']=np.round(XGB_df3.predict(train_df3_XGB))\n",
    "all_distributed_model_train_df4_actual_pred['XGB_model_pred']=np.round(XGB_df4.predict(train_df4_XGB))\n",
    "all_distributed_model_train_df5_actual_pred['XGB_model_pred']=np.round(XGB_df5.predict(train_df5_XGB))\n",
    "all_distributed_model_train_df6_actual_pred['XGB_model_pred']=np.round(XGB_df6.predict(train_df6_XGB))\n",
    "\n",
    "all_distributed_model_test_df1_actual_pred['XGB_model_pred']=np.round(XGB_df1.predict(test_df1_XGB))\n",
    "all_distributed_model_test_df2_actual_pred['XGB_model_pred']=np.round(XGB_df2.predict(test_df2_XGB))\n",
    "all_distributed_model_test_df3_actual_pred['XGB_model_pred']=np.round(XGB_df3.predict(test_df3_XGB))\n",
    "all_distributed_model_test_df4_actual_pred['XGB_model_pred']=np.round(XGB_df4.predict(test_df4_XGB))\n",
    "all_distributed_model_test_df5_actual_pred['XGB_model_pred']=np.round(XGB_df5.predict(test_df5_XGB))\n",
    "all_distributed_model_test_df6_actual_pred['XGB_model_pred']=np.round(XGB_df6.predict(test_df6_XGB))\n",
    "\n",
    "all_distributed_model_eval_df1_actual_pred['XGB_model_pred']=np.round(XGB_df1.predict(d_eval_df1))\n",
    "all_distributed_model_eval_df2_actual_pred['XGB_model_pred']=np.round(XGB_df2.predict(d_eval_df2))\n",
    "all_distributed_model_eval_df3_actual_pred['XGB_model_pred']=np.round(XGB_df3.predict(d_eval_df3))\n",
    "all_distributed_model_eval_df4_actual_pred['XGB_model_pred']=np.round(XGB_df4.predict(d_eval_df4))\n",
    "all_distributed_model_eval_df5_actual_pred['XGB_model_pred']=np.round(XGB_df5.predict(d_eval_df5))\n",
    "all_distributed_model_eval_df6_actual_pred['XGB_model_pred']=np.round(XGB_df6.predict(d_eval_df6))\n",
    "\n",
    "#evaluate train dataset\n",
    "XGB_train_1 = confusion_matrix(np.round(XGB_df1.predict(d_train_test_df1)),y_train_test_df1)\n",
    "XGB_train_2 = confusion_matrix(np.round(XGB_df2.predict(d_train_test_df2)),y_train_test_df2)\n",
    "XGB_train_3 = confusion_matrix(np.round(XGB_df3.predict(d_train_test_df3)),y_train_test_df3)\n",
    "XGB_train_4 = confusion_matrix(np.round(XGB_df4.predict(d_train_test_df4)),y_train_test_df4)\n",
    "XGB_train_5 = confusion_matrix(np.round(XGB_df5.predict(d_train_test_df5)),y_train_test_df5)\n",
    "XGB_train_6 = confusion_matrix(np.round(XGB_df6.predict(d_train_test_df6)),y_train_test_df6)\n",
    "conf_matrix_XGB_train=XGB_train_1 +XGB_train_2 + XGB_train_3 + XGB_train_4 + XGB_train_5 +XGB_train_6\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 XGB models for evaluation dataset\n",
    "XGB_eval_1 = confusion_matrix(np.round(XGB_df1.predict(d_eval_df1)),y_eval_df1)\n",
    "XGB_eval_2 = confusion_matrix(np.round(XGB_df2.predict(d_eval_df2)),y_eval_df2)\n",
    "XGB_eval_3 = confusion_matrix(np.round(XGB_df3.predict(d_eval_df3)),y_eval_df3)\n",
    "XGB_eval_4 = confusion_matrix(np.round(XGB_df4.predict(d_eval_df4)),y_eval_df4)\n",
    "XGB_eval_5 = confusion_matrix(np.round(XGB_df5.predict(d_eval_df5)),y_eval_df5)\n",
    "XGB_eval_6 = confusion_matrix(np.round(XGB_df6.predict(d_eval_df6)),y_eval_df6)\n",
    "conf_matrix_XGB_eval=XGB_eval_1 +XGB_eval_2 + XGB_eval_3 + XGB_eval_4 + XGB_eval_5 +XGB_eval_6\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 XGB modelsfor train dataset\n",
    "XGB_train_final_accuracy = (conf_matrix_XGB_train[0, 0] + conf_matrix_XGB_train[1, 1]) / np.sum(conf_matrix_XGB_train)\n",
    "XGB_train_final_precision = conf_matrix_XGB_train[0, 0] / (conf_matrix_XGB_train[0, 0] + conf_matrix_XGB_train[0, 1])\n",
    "XGB_train_final_sensitivity = conf_matrix_XGB_train[0, 0] / (conf_matrix_XGB_train[0, 0] + conf_matrix_XGB_train[1, 0])\n",
    "XGB_train_final_recall = conf_matrix_XGB_train[1, 1] / (conf_matrix_XGB_train[1, 1] + conf_matrix_XGB_train[0, 1])\n",
    "XGB_train_final_f1 = (2*conf_matrix_XGB_train[0, 0])/ ((2*conf_matrix_XGB_train[0, 0])+conf_matrix_XGB_train[1, 0]+conf_matrix_XGB_train[0, 1])\n",
    "XGB_train_perf=[np.round(XGB_train_final_accuracy,2),np.round(XGB_train_final_precision,2),np.round(XGB_train_final_sensitivity,2), np.round(XGB_train_final_recall,2),np.round(XGB_train_final_f1,2)]\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score of 6 XGB modelsfor evaluate dataset\n",
    "XGB_eval_final_accuracy = (conf_matrix_XGB_eval[0, 0] + conf_matrix_XGB_eval[1, 1]) / np.sum(conf_matrix_XGB_eval)\n",
    "XGB_eval_final_precision = conf_matrix_XGB_eval[0, 0] / (conf_matrix_XGB_eval[0, 0] + conf_matrix_XGB_eval[0, 1])\n",
    "XGB_eval_final_sensitivity = conf_matrix_XGB_eval[0, 0] / (conf_matrix_XGB_eval[0, 0] + conf_matrix_XGB_eval[1, 0])\n",
    "XGB_eval_final_recall = conf_matrix_XGB_eval[1, 1] / (conf_matrix_XGB_eval[1, 1] + conf_matrix_XGB_eval[0, 1])\n",
    "XGB_eval_final_f1 = (2*conf_matrix_XGB_eval[0, 0])/ ((2*conf_matrix_XGB_eval[0, 0])+conf_matrix_XGB_eval[1, 0]+conf_matrix_XGB_eval[0, 1])\n",
    "XGB_eval_perf=[np.round(XGB_eval_final_accuracy,2),np.round(XGB_eval_final_precision,2),np.round(XGB_eval_final_sensitivity,2),np.round(XGB_eval_final_recall,2),np.round(XGB_eval_final_f1,2)]\n",
    "\n",
    "# print('--------------------------train performance--------------------------------------------')\n",
    "print(conf_matrix_XGB_train)\n",
    "print('Accuracy, precision,sensitivity, recall, F1_score for distributed train data by same XGB models are the following:',np.round(XGB_train_perf,2))\n",
    "# print('--------------------------test performance--------------------------------------------')\n",
    "print(conf_matrix_XGB_eval)\n",
    "print('Accuracy, precision,sensitivity, recall, F1_score for distributed eval data by same XGB models are the following:',np.round(XGB_eval_perf,2))\n",
    "\n",
    "# store the end time\n",
    "finish_time = datetime.datetime.now()\n",
    "print('time taken for the hexa-distributed system using XGB model to run and produce outcomes:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fbf513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 6 datframes of train, test, evaluation into 3 datasets (train,test, evaluate)\n",
    "all_distributed_model_train_actual_pred=pd.concat([all_distributed_model_train_df1_actual_pred,all_distributed_model_train_df2_actual_pred,all_distributed_model_train_df3_actual_pred,all_distributed_model_train_df4_actual_pred,all_distributed_model_train_df5_actual_pred,all_distributed_model_train_df6_actual_pred], axis=0, ignore_index=True)\n",
    "all_distributed_model_test_actual_pred=pd.concat([all_distributed_model_test_df1_actual_pred,all_distributed_model_test_df2_actual_pred,all_distributed_model_test_df3_actual_pred,all_distributed_model_test_df4_actual_pred,all_distributed_model_test_df5_actual_pred,all_distributed_model_test_df6_actual_pred], axis=0, ignore_index=True)\n",
    "all_distributed_model_eval_actual_pred=pd.concat([all_distributed_model_eval_df1_actual_pred,all_distributed_model_eval_df2_actual_pred,all_distributed_model_eval_df3_actual_pred,all_distributed_model_eval_df4_actual_pred,all_distributed_model_eval_df5_actual_pred,all_distributed_model_eval_df6_actual_pred], axis=0, ignore_index=True)\n",
    "\n",
    "# set up directory\n",
    "os.chdir(\"C:\\\\Users\\\\25273141\\\\OneDrive - Edge Hill University\\\\Distributed Model Project\\\\Loan Data\")\n",
    "\n",
    "#export actual and predicted labels of single model and distributed model \n",
    "all_single_model_raw_train_actual_pred.to_csv('all_single_model_raw_train_actual_pred.csv',index=False)\n",
    "all_single_model_raw_test_actual_pred.to_csv('all_single_model_raw_test_actual_pred.csv',index=False)\n",
    "all_single_model_raw_eval_actual_pred.to_csv('all_single_model_raw_eval_actual_pred.csv',index=False)\n",
    "all_distributed_model_train_actual_pred.to_csv('all_distributed_model_train_actual_pred.csv',index=False)\n",
    "all_distributed_model_test_actual_pred.to_csv('all_distributed_model_test_actual_pred.csv',index=False)\n",
    "all_distributed_model_eval_actual_pred.to_csv('all_distributed_model_eval_actual_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a61fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
